{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas 소개 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GonsSu24 내용에 이어서 Pandas 라이브러리를 소개한다.\n",
    "\n",
    "먼저 GongSu24를 임포트 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GongSu24_Pandas_Introduction_1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뷰 방식 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame의 색인을 이용해서 생성된 칼럼은 내부 데이터에 대한 뷰(view)이며 복사가 이루어지지 않는다. 따라서 이렇게 얻은 Series 객체에 대한 변경은 실제 DataFrame에 반영된다. 복사본이 필요할 때는 Series의 copy 메서드를 이용하자.\n",
    "\n",
    "또한 중첩된 사전을 이용하여 데이터를 생성할 수 있는데, 다음과 같은 중첩한 사전이 있다면."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop = {'Nevada' : {2001: 2.4, 2002: 2.9},\n",
    "       'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바깥에 있는 사전의 키 값이 칼럼이 되고 안에 있는 키는 로우가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nevada  Ohio\n",
       "2000     NaN   1.5\n",
       "2001     2.4   1.7\n",
       "2002     2.9   3.6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe5 = DataFrame(pop)\n",
    "dframe5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy에서와 마찬가지로 결과 값의 순서를 뒤집을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2000  2001  2002\n",
       "Nevada   NaN   2.4   2.9\n",
       "Ohio     1.5   1.7   3.6"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame3T = frame3.T.copy()\n",
    "frame3T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전치행렬: 뷰 방식을 따름. 대신에 copy() 함수를 사용하면 관계를 끊을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nevada  Ohio\n",
       "2000     1.0   1.5\n",
       "2001     2.4   1.7\n",
       "2002     2.9   3.6"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame3['Nevada'].iloc[0] = 1.0\n",
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2000  2001  2002\n",
       "Nevada   NaN   2.4   2.9\n",
       "Ohio     1.5   1.7   3.6"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame3T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중첩된 사전을 이용해서 DataFrame을 생성할 때 안쪽에 있는 사전 값은 키 값별로 조합되어 결과의 색인이 되지만 색인을 직접 지정한다면 지정된 색인으로 DataFrame을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nevada  Ohio\n",
       "2001     2.4   1.7\n",
       "2002     2.9   3.6\n",
       "2003     NaN   NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(pop, index=[2001, 2002, 2003])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series 객체를 담고 있는 사전 데이터도 같은 방식으로 취급된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nevada</th>\n",
       "      <th>ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nevada  ohio\n",
       "2000     NaN   1.5\n",
       "2001     2.4   1.7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata = {'ohio' : frame3['Ohio'][:-1],\n",
    "         'Nevada': frame3['Nevada'][:2]}\n",
    "DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 생성자에 넘길 수 있는 자료형의 목록은 [표 5-1]을 참고하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>state</th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state  Nevada  Ohio\n",
       "year               \n",
       "2000      NaN   1.5\n",
       "2001      2.4   1.7\n",
       "2002      2.9   3.6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame3.index.name = 'year'; frame3.columns.name = 'state'\n",
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series와 유사하게 values 속성은 DataFrame에 저장된 데이터를 2차원 배열로 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  1.5],\n",
       "       [ 2.4,  1.7],\n",
       "       [ 2.9,  3.6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame의 칼럼에 서로 다른 dtype이 있다면 모든 칼럼을 수용하기 위해 그 칼럼 배열의 dtype이 선택된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000, 'Ohio', 1.5, nan],\n",
       "       [2001, 'Ohio', 1.7, -1.2],\n",
       "       [2002, 'Ohio', 3.6, nan],\n",
       "       [2001, 'Nevada', 2.4, -1.5],\n",
       "       [2002, 'Nevada', 2.9, -1.7]], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 색인 개체\n",
    "pandas의 색인 객체는 표 형식의 데이터에서 각 로우와 칼럼에 대한 이름과 다른 메타데이터(축의 이름등)를 저장하는 객체다. Series나 DataFrame 객체를 생성할 때 사용되는 배열이나 혹은 다른 순차적인 이름은 내부적으로 색인으로 변환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'a', u'b', u'c'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = Series(range(3), index=['a', 'b', 'c'])\n",
    "index = obj.index\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'b', u'c'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색인 객체는 변경할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-676fdeb26a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gslee/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index does not support mutable operations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index does not support mutable operations"
     ]
    }
   ],
   "source": [
    "index[1] = 'd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색인 객체는 변경될 수 없기에 자료 구조 사이에서 안전하게 공유될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2], dtype='int64')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.Index(np.arange(3))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2= Series([1.5, -2.5, 0], index=index)\n",
    "obj2.index is index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특수한 목적으로 축을 색인하는 기능을 개발하기 위해 Index 클래스의 서브클래스를 만들 수 있다.\n",
    "\n",
    "또한 배열과 유사하게 Index 객체도 고정 크기로 동작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>state</th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state  Nevada  Ohio\n",
       "year               \n",
       "2000      NaN   1.5\n",
       "2001      2.4   1.7\n",
       "2002      2.9   3.6"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Ohio' in frame3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2003 in frame3.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 색인은 담고 있는 데이터에 대한 정보를 취급하는 여러 가지 메서드와 속성을 가지고 있다. [표 5-3]을 참고하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 핵심 기능\n",
    "이 절에서는 Series나 DataFrame에 저장된 데이터를 다루는 기본 방법을 설명한다. 앞으로 pandas를 이용한 데이터 분석과 조작에 관한 좀 더 자세한 내용을 살펴볼 것이다. 이 책은 pandas 라이브러리에 대한 완전한 설명은 자제하고 중요한 기능에만 초점을 맞추고 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 재색인\n",
    "pandas객체의 기막힌 기능 중 하나인 reindex는 새로운 색인에 맞도록 객체를 새로 생성하는 기능이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    4.5\n",
       "b    7.2\n",
       "a   -5.3\n",
       "c    3.6\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = Series([4.5, 7.2, -5.3, 3.6], index= ['d', 'b', 'a', 'c'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 Series 객체에 대해 reindex를 호충하면 데이터를 새로운 색인에 맞게 재배열하고, 없는 값이 있다면 비어있는 값을 새로 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -5.3\n",
       "b    7.2\n",
       "c    3.6\n",
       "d    4.5\n",
       "e    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -5.3\n",
       "b    7.2\n",
       "c    3.6\n",
       "d    4.5\n",
       "e    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.reindex(['a','b','c','d','e'], fill_value=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시계열 같은 순차적인 데이터를 재색인할 때 값을 보간하거나 채워 넣어야 할 경우가 있다. 이런 경우 method 옵션을 이용해서 해결할 수 있으며, ffill 메서드를 이용하면 앞의 값으로 누락된 값을 채워넣을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      blue\n",
       "1      blue\n",
       "2    purple\n",
       "3    purple\n",
       "4    yellow\n",
       "5    yellow\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj3 = Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])\n",
    "obj3.reindex(range(6), method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 누락된 값을 앞이나 뒤에 채워 넣는 것보다 좀 더 세련된 방법으로 보간할 수 있는 방법을 추후 추가할 필요가 있다.\n",
    "\n",
    "DataFrame에 대한 reindex는 (로우) 색인, 칼럼 또는 둘 다 변경이 가능하다. 그냥 순서만 전달하면 로우가 재색인된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Texas</th>\n",
       "      <th>California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ohio  Texas  California\n",
       "a     0      1           2\n",
       "b     3      4           5\n",
       "d     6      7           8"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'b', 'd'],\\\n",
    "                    columns= ['Ohio', 'Texas', 'California'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Texas</th>\n",
       "      <th>California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ohio  Texas  California\n",
       "a   0.0    1.0         2.0\n",
       "b   3.0    4.0         5.0\n",
       "c   NaN    NaN         NaN\n",
       "d   6.0    7.0         8.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2 = frame.reindex(['a', 'b', 'c', 'd'])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "열은 columns 예약어를 사용해서 재색인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texas</th>\n",
       "      <th>Utah</th>\n",
       "      <th>California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Texas  Utah  California\n",
       "a      1   NaN           2\n",
       "b      4   NaN           5\n",
       "d      7   NaN           8"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = ['Texas', 'Utah', 'California']\n",
    "frame.reindex(columns=states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보간은 로우에 대해서만 이루어진다 (axis 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Texas</th>\n",
       "      <th>California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ohio  Texas  California\n",
       "a     0      1           2\n",
       "b     3      4           5\n",
       "c     3      4           5\n",
       "d     6      7           8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.reindex(index=['a', 'b', 'c', 'd'], method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reindex는 기존 자료를 변경하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Texas</th>\n",
       "      <th>California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ohio  Texas  California\n",
       "a     0      1           2\n",
       "b     3      4           5\n",
       "d     6      7           8"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재색인은 ix를 이용해서 라벨로 색인하면 좀 더 간결하게 할 수 있다.\n",
    "\n",
    "In[124]: frame.ix[['a', 'b', 'c', 'd'], states]\n",
    "Out[122]: \n",
    "   Texas  Utah  California\n",
    "a      1   NaN           2\n",
    "b      4   NaN           5\n",
    "c    NaN   NaN         NaN\n",
    "d      7   NaN           8\n",
    "\n",
    "5.2.2 하나의 로우 또는 칼럼 삭제하기\n",
    "\n",
    "색인 배열 또는 삭제하려는 로우나 칼럼이 제외된 리스트를 이미 가지고 있다면 로우나 칼럼을 쉽게 삭제할 수 있는데, 이 방법은 데이터의 모양을 변경하는 작업이 필요하다.\n",
    "drop 메서드를 사용하면 선택한 값이 삭제된 새로운 개체를 얻을 수 있다.\n",
    "\n",
    "In[125]: obj = Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])\n",
    "In[126]: new_obj = obj.drop('c')\n",
    "In[127]: new_obj\n",
    "Out[125]: \n",
    "a    0\n",
    "b    1\n",
    "d    3\n",
    "e    4\n",
    "dtype: float64\n",
    "In[128]: obj.drop(['d', 'c'])\n",
    "Out[126]: \n",
    "a    0\n",
    "b    1\n",
    "e    4\n",
    "dtype: float64\n",
    "DataFrame에서는 로우와 칼럼 모두에서 값을 삭제할 수 있다.\n",
    "In[130]: data.drop(['Colorado', 'Ohio'])\n",
    "Out[128]: \n",
    "          one  two  three  four\n",
    "Utah        8    9     10    11\n",
    "New York   12   13     14    15\n",
    "In[131]: data.drop('two', axis=1)\n",
    "Out[129]: \n",
    "          one  three  four\n",
    "Ohio        0      2     3\n",
    "Colorado    4      6     7\n",
    "Utah        8     10    11\n",
    "New York   12     14    15\n",
    "In[132]: data.drop(['two', 'four'], axis=1)\n",
    "Out[130]: \n",
    "          one  three\n",
    "Ohio        0      2\n",
    "Colorado    4      6\n",
    "Utah        8     10\n",
    "New York   12     14\n",
    "\n",
    "5.2.3 색인하기, 선택하기, 거르기\n",
    "\n",
    "Series의 색인 (obj[...])은 NumPy 배열의 색인과 유사하게 동작하는데, Series의 색인은 정수가 아니어도 된다는 점이 다르다.  \n",
    "\n",
    "라벨 이름으로 슬라이싱하는 것은 시작점과 끝점을 포함한다는 점이 일반 파이선에서 슬라이싱과 다른 점이다.\n",
    "\n",
    "In[136]: obj = Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\n",
    "In[137]: obj['b':'c']\n",
    "Out[135]: \n",
    "b    1\n",
    "c    2\n",
    "dtype: float64\n",
    "슬라이싱 문법으로 선택된 영역에 값을 대입하는 것은 예상한 대로 동작한다.\n",
    "\n",
    "In[138]: obj['b':'c'] = 5\n",
    "In[139]: obj\n",
    "Out[137]: \n",
    "a    0\n",
    "b    5\n",
    "c    5\n",
    "d    3\n",
    "dtype: float64\n",
    "앞에서 확인한대로 색인으로 DataFrame에서 칼럼의 값을 하나 이상 가져올 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[140]: data = DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
    "                 columns = ['one', 'two', 'three', 'four'])\n",
    "In[141]: data\n",
    "Out[139]: \n",
    "          one  two  three  four\n",
    "Ohio        0    1      2     3\n",
    "Colorado    4    5      6     7\n",
    "Utah        8    9     10    11\n",
    "New York   12   13     14    15\n",
    "In[142]: data['two']\n",
    "Out[140]: \n",
    "Ohio         1\n",
    "Colorado     5\n",
    "Utah         9\n",
    "New York    13\n",
    "Name: two, dtype: int32\n",
    "In[143]: data[['three', 'one']]\n",
    "Out[141]: \n",
    "          three  one\n",
    "Ohio          2    0\n",
    "Colorado      6    4\n",
    "Utah         10    8\n",
    "New York     14   12\n",
    "\n",
    "슬라이싱으로 로우를 선택하거나 불리언 배열로 칼럼을 선택할 수 있다.\n",
    "\n",
    "In[144]: data[:2]\n",
    "Out[142]: \n",
    "          one  two  three  four\n",
    "Ohio        0    1      2     3\n",
    "Colorado    4    5      6     7\n",
    "In[145]: data[data['three'] > 5]\n",
    "Out[143]: \n",
    "          one  two  three  four\n",
    "Colorado    4    5      6     7\n",
    "Utah        8    9     10    11\n",
    "New York   12   13     14    15\n",
    "\n",
    "이 문법에 모순이 있다고 생각할 수 있지만, 실용성에 기인한 것일 뿐이다.\n",
    "\n",
    "또 다른 사례는 스칼라 비교를 통해 생성된 불리언 DataFrame을 사용해서 값을 선택하는 것이다.\n",
    "\n",
    "In[146]: data < 5\n",
    "Out[144]: \n",
    "            one    two  three   four\n",
    "Ohio       True   True   True   True\n",
    "Colorado   True  False  False  False\n",
    "Utah      False  False  False  False\n",
    "New York  False  False  False  False\n",
    "In[147]: data[data < 5] = 0\n",
    "In[148]: data\n",
    "Out[146]: \n",
    "          one  two  three  four\n",
    "Ohio        0    0      0     0\n",
    "Colorado    0    5      6     7\n",
    "Utah        8    9     10    11\n",
    "New York   12   13     14    15\n",
    "이 예제는 DataFrame을 ndarray와 문법적으로 비슷하게 보이도록 의도한 것이다.\n",
    "\n",
    "DataFrame의 칼럼에 대해 라벨로 색인하는 방법으로, 특수한 색인 필드인 ix를 소개한다. ix는 NumPy와 비슷한 방식에 추가적으로 축의 라벨을 사용하여 DataFrame의 로우와 칼럼을 선택할 수 있도록 한다. 앞에서 언급했듯이 이 방법은 재색인을 좀 더 간단하게 할 수 있는 방법이다.\n",
    "In[149]: data.ix['Colorado', ['two', 'three']]\n",
    "Out[147]: \n",
    "two      5\n",
    "three    6\n",
    "Name: Colorado, dtype: int32\n",
    "In[150]: data.ix[['Colorado', 'Utah'], [3,0,1]]\n",
    "Out[148]: \n",
    "          four  one  two\n",
    "Colorado     7    0    5\n",
    "Utah        11    8    9\n",
    "In[151]: data.ix[2]\n",
    "Out[149]: \n",
    "one       8\n",
    "two       9\n",
    "three    10\n",
    "four     11\n",
    "Name: Utah, dtype: int32\n",
    "In[152]: data.ix[:'Utah', 'two']\n",
    "Out[150]: \n",
    "Ohio        0\n",
    "Colorado    5\n",
    "Utah        9\n",
    "Name: two, dtype: int32\n",
    "In[153]: data.ix[data.three > 5, :3]\n",
    "Out[151]: \n",
    "          one  two  three\n",
    "Colorado    0    5      6\n",
    "Utah        8    9     10\n",
    "New York   12   13     14\n",
    "지금까지 살펴봤듯이 pandas 객체에서 데이터를 선택하고 재배열하는 방법은 여러 가지가 있다. [표 5-6]에 다양한 방법을 정리해두었다. 나중에 살펴볼 계층적 색인을 이용하면 좀 더 다양한 방법을 사용할 수 있다.\n",
    "\n",
    "5.2.4 산술연산과 데이터 정렬\n",
    "pandas에서 중요한 기능은 색인이 다른 객체 간의 산술연산이다. 객체를 더할 때 짝이 맞지 않는 색인이 있다면 결과에 두 색인이 통합된다.\n",
    "\n",
    "In[159]: s1 = Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd','e'])\n",
    "In[160]: s2 = Series([-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'])\n",
    "In[161]: s1 + s2\n",
    "Out[159]: \n",
    "a    5.2\n",
    "c    1.1\n",
    "d    NaN\n",
    "e    0.0\n",
    "f    NaN\n",
    "g    NaN\n",
    "dtype: float64\n",
    "\n",
    "서로 겹치는 색인이 없다면 데이터는 NA 값이 된다. 산술연산 시 누락된 값은 전파되며, DataFrame에서는 로우와 칼럼 모두에 적용된다.\n",
    "In[162]: df1 = DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'),\n",
    "                index=['Ohio', 'Texas', 'Colorado'])\n",
    "In[163]: df2 = DataFrame(np.arange(12.).reshape((4,3)), columns=list('bde'),\n",
    "                         index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "\n",
    "In[164]: df1 + df2\n",
    "Out[162]: \n",
    "           b   c   d   e\n",
    "Colorado NaN NaN NaN NaN\n",
    "Ohio       3 NaN   6 NaN\n",
    "Oregon   NaN NaN NaN NaN\n",
    "Texas      9 NaN  12 NaN\n",
    "Utah     NaN NaN NaN NaN\n",
    "산술연산 메서드에 채워 넣을 값 지정하기\n",
    "\n",
    "서로 다른 색인을 가지는 객체 간의 산술연산에서 존재하지 않는 축의 값을 특수한 값( 0 같은)으로 지정하고 싶을 때는 다음과 같이 할 수 있다.\n",
    "\n",
    "In[168]: df1 = DataFrame(np.arange(12.).reshape((3,4)), columns=list('abcd'))\n",
    "df2 = DataFrame(np.arange(20.).reshape((4,5)), columns=list('abcde'))\n",
    "In[169]: df1\n",
    "Out[167]: \n",
    "   a  b   c   d\n",
    "0  0  1   2   3\n",
    "1  4  5   6   7\n",
    "2  8  9  10  11\n",
    "In[170]: df2\n",
    "Out[168]: \n",
    "    a   b   c   d   e\n",
    "0   0   1   2   3   4\n",
    "1   5   6   7   8   9\n",
    "2  10  11  12  13  14\n",
    "3  15  16  17  18  19\n",
    "In[171]: df1 + df2\n",
    "Out[169]: \n",
    "    a   b   c   d   e\n",
    "0   0   2   4   6 NaN\n",
    "1   9  11  13  15 NaN\n",
    "2  18  20  22  24 NaN\n",
    "3 NaN NaN NaN NaN NaN\n",
    "이 둘을 더했을 때 겹치지 않는 부분의 값이 NA값이 된 것을 알 수 있다.\n",
    "\n",
    "df1의 add메서드로 df2와 fill_value 값을 인자로 전달한다.\n",
    "\n",
    "In[172]: df1.add(df2, fill_value=0)\n",
    "\n",
    "Out[170]: \n",
    "    a   b   c   d   e\n",
    "0   0   2   4   6   4\n",
    "1   9  11  13  15   9\n",
    "2  18  20  22  24  14\n",
    "3  15  16  17  18  19\n",
    "In[173]: df1.reindex(columns=df2.columns, fill_value=0)\n",
    "\n",
    "Out[171]: \n",
    "   a  b   c   d  e\n",
    "0  0  1   2   3  0\n",
    "1  4  5   6   7  0\n",
    "2  8  9  10  11  0\n",
    "\n",
    "Series나 DataFrame을 재색인할 때 역시 fill_value를 지정할 수 있다.\n",
    "\n",
    "DataFrame과 Series 간의 연산\n",
    "\n",
    "NumPy 배열의 연산처럼 DataFrame과 Series 간의 연산도 잘 정의되어 있다. 먼저 2차원 배열과 그 배열 중 한 칼럼의 차이에 대해서 생각할 수 있는 예제를 살펴보자.\n",
    "\n",
    "In[175]: arr\n",
    "Out[173]: \n",
    "array([[  0.,   1.,   2.,   3.],\n",
    "       [  4.,   5.,   6.,   7.],\n",
    "       [  8.,   9.,  10.,  11.]])\n",
    "In[176]: arr[0]\n",
    "Out[174]: array([ 0.,  1.,  2.,  3.])\n",
    "In[177]: arr - arr[0]\n",
    "Out[175]: \n",
    "array([[ 0.,  0.,  0.,  0.],\n",
    "       [ 4.,  4.,  4.,  4.],\n",
    "       [ 8.,  8.,  8.,  8.]])\n",
    "이 예제는 브로드캐스팅에 대한 예제로 자세한 내용은 12장에서 살펴볼 것이다. DataFrame과 Series간의 연산은 이와 유사하다.\n",
    "\n",
    "In[6]: frame = DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'),\n",
    "                  index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "In[7]: series = frame.ix[0]\n",
    "In[8]: frame\n",
    "Out[8]: \n",
    "        b   d   e\n",
    "Utah    0   1   2\n",
    "Ohio    3   4   5\n",
    "Texas   6   7   8\n",
    "Oregon  9  10  11\n",
    "In[9]: series\n",
    "Out[9]: \n",
    "b    0\n",
    "d    1\n",
    "e    2\n",
    "Name: Utah, dtype: float64\n",
    "기본적으로 DataFrame과 Series 간의 산술 연산은 Series의 색인을 DataFrame의 칼럼에 맞추고 아래 로우로 전파한다.\n",
    "\n",
    "In[10]: frame - series\n",
    "Out[10]: \n",
    "        b  d  e\n",
    "Utah    0  0  0\n",
    "Ohio    3  3  3\n",
    "Texas   6  6  6\n",
    "Oregon  9  9  9\n",
    "만약 색인 값을 DataFrame의 칼럼이나 Series의 색인에서 찾을 수 없다면 그 객체는 형식을 맞추기 위해 재색인된다.\n",
    "\n",
    "In[11]: series2 = Series(range(3), index = list('bef'))\n",
    "In[12]: frame + series2\n",
    "Out[12]: \n",
    "        b   d   e   f\n",
    "Utah    0 NaN   3 NaN\n",
    "Ohio    3 NaN   6 NaN\n",
    "Texas   6 NaN   9 NaN\n",
    "Oregon  9 NaN  12 NaN\n",
    "만약 각 로우에 대해 연산을 수행하고 싶다면 산술연산 메서드를 사용하면 된다.\n",
    "In[17]: series3 = frame['d']\n",
    "\n",
    "In[18]: frame\n",
    "\n",
    "Out[18]: \n",
    "        b   d   e\n",
    "Utah    0   1   2\n",
    "Ohio    3   4   5\n",
    "Texas   6   7   8\n",
    "Oregon  9  10  11\n",
    "In[19]: series3\n",
    "\n",
    "Out[19]: \n",
    "Utah       1\n",
    "Ohio       4\n",
    "Texas      7\n",
    "Oregon    10\n",
    "Name: d, dtype: float64\n",
    "In[20]: frame.sub(series3, axis=0)\n",
    "\n",
    "Out[20]: \n",
    "        b  d  e\n",
    "Utah   -1  0  1\n",
    "Ohio   -1  0  1\n",
    "Texas  -1  0  1\n",
    "Oregon -1  0  1\n",
    "\n",
    "5.2.5 함수 적용과 매핑\n",
    "pandas 객체에도 NumPy의 유니버설 함수( 배열의 각 원소에 적용되는 메서드)를 적용할 수 있다.\n",
    "\n",
    "In[21]: frame = DataFrame(np.random.randn(4,3), columns=list('bde'),\n",
    "                  index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "In[22]: frame\n",
    "Out[22]: \n",
    "               b         d         e\n",
    "Utah   -1.077549  1.063706  1.300466\n",
    "Ohio   -0.028174 -0.805961  1.124684\n",
    "Texas   0.884636 -0.271803  0.133528\n",
    "Oregon -1.284909  0.136602  0.705397\n",
    "In[23]: np.abs(frame) #절대값\n",
    "Out[23]: \n",
    "               b         d         e\n",
    "Utah    1.077549  1.063706  1.300466\n",
    "Ohio    0.028174  0.805961  1.124684\n",
    "Texas   0.884636  0.271803  0.133528\n",
    "Oregon  1.284909  0.136602  0.705397\n",
    "자주 사용되는 또 다른 연산은 각 로우나 칼럼의 1차원 배열에 함수를 적용하는 것이다.\n",
    "DataFrame의 apply 메서드를 통해 수행할 수 있다.\n",
    "\n",
    "In[24]: f = lambda x: x.max() - x.min()\n",
    "In[25]: frame.apply(f)\n",
    "Out[25]: \n",
    "b    2.169545\n",
    "d    1.869667\n",
    "e    1.166938\n",
    "dtype: float64\n",
    "In[26]: frame.apply(f, axis=1)\n",
    "Out[26]: \n",
    "Utah      2.378015\n",
    "Ohio      1.930645\n",
    "Texas     1.156440\n",
    "Oregon    1.990306\n",
    "dtype: float64\n",
    "배열의 합계나 평균 같은 일반적인 통계는 DataFrame의 메서드로 있으므로 apply 메서드를 사용해야만 하는 것은 아니다.\n",
    "\n",
    "apply 메서드에 전달된 함수는 스칼라 값을 반환할 필요가 없으며, Series 또는 여러 값을 반환해도 된다.\n",
    "In[27]: def f(x):\n",
    "    return Series([x.min(), x.max()], index=['min', 'max'])\n",
    "In[28]: frame.apply(f)\n",
    "Out[28]: \n",
    "            b         d         e\n",
    "min -1.284909 -0.805961  0.133528\n",
    "max  0.884636  1.063706  1.300466\n",
    "배열의 각 원소에 적용되는 파이썬의 함수를 사용할 수도 있다. frame 객체에서 실수 값을 문자열 포맷으로 변환하고 싶다면 applymap을 이용해서 다음과 같이 해도 된다.\n",
    "\n",
    "In[31]: format = lambda x: '%.2f' % x\n",
    "In[32]: frame.applymap(format)\n",
    "Out[32]: \n",
    "            b      d     e\n",
    "Utah    -1.08   1.06  1.30\n",
    "Ohio    -0.03  -0.81  1.12\n",
    "Texas    0.88  -0.27  0.13\n",
    "Oregon  -1.28   0.14  0.71\n",
    "이 메서드의 이름이 applymap인 이유는 Series가 각 원소에 적용할 함수를 지정하기 위한 map 메서드를 가지고 있기 때문이다.\n",
    "\n",
    "In[35]: frame['e'].map(format)\n",
    "Out[35]: \n",
    "Utah      1.30\n",
    "Ohio      1.12\n",
    "Texas     0.13\n",
    "Oregon    0.71\n",
    "Name: e, dtype: object\n",
    "\n",
    "5.2.6 정렬과 순위\n",
    "\n",
    "어떤 기준에 근거해서 데이터를 정렬하는 것 역시 중요한 명령이다. 로우나 칼럼의 색인을 알파벳 순으로 정렬하려면 정렬된 새로운 객체를 반화하는 sort_index 메서드를 사용하면 된다.\n",
    "\n",
    "In[35]: frame['e'].map(format)\n",
    "Out[35]: \n",
    "Utah      1.30\n",
    "Ohio      1.12\n",
    "Texas     0.13\n",
    "Oregon    0.71\n",
    "Name: e, dtype: object\n",
    " \n",
    "5.2.6\n",
    "어떤 기준에 근거해서 데이터를 정렬하는 것 역시 중요한 명령이다. 로우나 칼럼의 색인을 알파벳 순으로 정렬하려면 정렬된 새로운 객체를 반환하는 sort_index 메서드를 사용하면 된다.\n",
    " \n",
    "In[36]: obj = Series(range(4), index=['d', 'a', 'b', 'c'])\n",
    "In[37]: obj.sort_index()\n",
    "Out[37]: \n",
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "d    0\n",
    "dtype: int64\n",
    " \n",
    "DataFrame은 로우나 칼럼 중 하나의 축을 기준으로 정렬할 수 있다.\n",
    "In[40]: frame = DataFrame(np.arange(8).reshape((2,4)), index = ['three', 'one'], columns = ['d', 'a', 'b', 'c'])\n",
    "\n",
    "In[41]: frame.sort_index()\n",
    "Out[41]: \n",
    "       d  a  b  c\n",
    "one    4  5  6  7\n",
    "three  0  1  2  3\n",
    "\n",
    "In[42]: frame.sort_index(axis=1)\n",
    "Out[42]: \n",
    "       a  b  c  d\n",
    "three  1  2  3  0\n",
    "one    5  6  7  4\n",
    " \n",
    "데이터는 기본적으로 오름차순으로 정렬되지만 내림차순으로 정렬할 수도 있다.\n",
    "In[43]: frame.sort_index(axis=1, ascending=False)\n",
    "\n",
    "Out[43]: \n",
    "\n",
    "       d  c  b  a\n",
    "\n",
    "three  0  3  2  1\n",
    "\n",
    "one    4  7  6  5\n",
    " \n",
    "Series 객체를 값에 따라 정렬하고 싶다면 sort_values 메서드를 사용한다.\n",
    "In[46]: obj.sort_values()\n",
    "Out[46]: \n",
    "2   -3\n",
    "3    2\n",
    "0    4\n",
    "1    7\n",
    "dtype: int64\n",
    "In[47]: obj = Series([4, 7, -3, 2])\n",
    "In[48]: obj.sort_values()\n",
    "Out[48]: \n",
    "2   -3\n",
    "3    2\n",
    "0    4\n",
    "1    7\n",
    "dtype: int64\n",
    " \n",
    "정렬할 때 비어있는 값은 기본적으로 Series 객체에서 가장 마지막에 위치한다.\n",
    "In[49]: obj = Series([4, np.nan, 7, np.nan, -3, 2])\n",
    "In[50]: obj.sort_values()\n",
    "Out[50]: \n",
    "4    -3\n",
    "5     2\n",
    "0     4\n",
    "2     7\n",
    "1   NaN\n",
    "3   NaN\n",
    "dtype: float64\n",
    " \n",
    "DataFrame에서는 하나 이상의 칼럼에 있는 값으로 정렬이 필요할 수 있다. 이럴 때는 by 옵션에 필요한 칼럼의 이름을 넘기면 된다.\n",
    "In[34]: frame = DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\n",
    "In[35]: frame\n",
    "Out[33]: \n",
    "   a  b\n",
    "0  0  4\n",
    "1  1  7\n",
    "2  0 -3\n",
    "3  1  2\n",
    "In[36]: frame.sort_values(by='b')\n",
    "Out[34]: \n",
    "   a  b\n",
    "2  0 -3\n",
    "3  1  2\n",
    "0  0  4\n",
    "1  1  7\n",
    "여러 개의 칼럼을 정렬하려면 칼럼의 이름이 담긴 리스트를 전달하면 된다.\n",
    "In[37]: frame.sort_values(by=['a','b'])\n",
    "Out[35]: \n",
    "   a  b\n",
    "2  0 -3\n",
    "0  0  4\n",
    "3  1  2\n",
    "1  1  7\n",
    "순위는 정렬과 거의 흡사하며, 1부터 배열의 유효한 데이터 개수까지 순위를 매긴다. 또한 순위는 numpy.argsort에서 반환하는 간접 정렬 색인과 유사한데, 동률인 순위를 처리하는 방식이 다르다. 기본적으로 Series와 DataFrame의 rank 메서드는 동점인 항목에 대해서는 평균 순위를 매긴다.\n",
    "\n",
    "In[38]: obj = Series([7, -5, 7, 4, 2, 0 ,4])\n",
    "In[39]: obj.rank()\n",
    "Out[37]:\n",
    "0    6.5\n",
    "1    1.0\n",
    "2    6.5\n",
    "3    4.5\n",
    "4    3.0\n",
    "5    2.0\n",
    "6    4.5\n",
    "dtype: float64\n",
    "데이터 상에서 나타나는 순서에 따라 순위를 매길 수도 있다. \n",
    "In[40]: obj.rank(method='first')\n",
    "Out[38]: \n",
    "0    6\n",
    "1    1\n",
    "2    7\n",
    "3    4\n",
    "4    3\n",
    "5    2\n",
    "6    5\n",
    "dtype: float64\n",
    "내림차순으로 순위를 매길 수도 있다.\n",
    "In[41]: obj.rank(ascending=False, method='max')\n",
    " # 'max' 는 같은 값을 가지는 그룹을 높은 순위로 매긴다.\n",
    "Out[39]: \n",
    "0    2\n",
    "1    7\n",
    "2    2\n",
    "3    4\n",
    "4    5\n",
    "5    6\n",
    "6    4\n",
    "dtype: float64\n",
    "\n",
    "5.2.7 중복 색인\n",
    "지금까지 살펴본 모든 예제는 모두 축의 이름(색인 값)이 유일했다.\n",
    "pandas의 많은 함수(reindex 같은) 에서 색인 값은 유일해야 하지만 강제 사항은 아니다. 이제 색인 값이 중복된 Series객체를 살펴보자.\n",
    "In[42]: obj = Series(range(5), index=['a', 'a', 'b', 'b', 'c'])\n",
    "In[43]: obj\n",
    "Out[41]: \n",
    "a    0\n",
    "a    1\n",
    "b    2\n",
    "b    3\n",
    "c    4\n",
    "dtype: int64\n",
    "색인의 is_unique 속성은 해당 값이 유일한지 아닌지 알려준다.\n",
    "In[44]: obj.index.is_unique\n",
    "Out[42]: False\n",
    "\n",
    "중복되는 색인 값이 있으면 색인을 이용한 데이터 선택은 다르게 동작하고 하나의 Series 객체를 반환한다. 하지만 중복되는 색인 값이 없으면 색인을 이용한 데이터 선택은 스칼라 값을 반환한다.\n",
    "\n",
    "In[45]: obj['a']\n",
    "Out[43]: \n",
    "a    0\n",
    "a    1\n",
    "dtype: int64\n",
    "In[46]: obj['c']\n",
    "Out[44]: 4\n",
    "\n",
    "DataFrame에서 로우를 선택하는 것도 동일하다.\n",
    "In[47]: df = DataFrame(np.random.randn(4, 3), index=['a', 'a', 'b','b'])\n",
    "In[48]: df\n",
    "Out[46]: \n",
    "          0         1         2\n",
    "a  2.053621  0.432342  0.236329\n",
    "a -0.843233  2.030160  0.603298\n",
    "b -0.487331  0.949086 -0.163972\n",
    "b -2.950345 -0.615662 -1.235880\n",
    "In[49]: df.ix['b']\n",
    "\n",
    "Out[47]: \n",
    "          0         1         2\n",
    "b -0.487331  0.949086 -0.163972\n",
    "b -2.950345 -0.615662 -1.235880\n",
    "5.3 기술통계 계산과 요약\n",
    "\n",
    "pandas 객체는 일반적인 수학 메서드와 통계 메서드를 가지고 있다. 이 메서드는 대부분 Series나 DataFrame 하나의 칼럼이나 로우에서 단일 값(합이나 평균 같은)을 구하는 축소 혹은 요약통계 범주에 속한다. 순수 NumPy 배열에서 제공하는 동일한 메서드와 비교하여 pandas의 메서드는 처음부터 누락된 데이터를 제외하도록 설계되었다. 다음과 같은 DataFrame을 생각해보자\n",
    "\n",
    "In[50]: df = DataFrame([[1.4, np.nan],[7.1, -4.5],[np.nan, np.nan], [0.75, -1.3]],\n",
    "               index = ['a', 'b', 'c', 'd'],\n",
    "               columns=['one', 'two'])\n",
    "In[51]: df\n",
    "Out[49]: \n",
    "    one  two\n",
    "a  1.40  NaN\n",
    "b  7.10 -4.5\n",
    "c   NaN  NaN\n",
    "d  0.75 -1.3\n",
    "\n",
    "DataFrame의 sum 메서드를 호출하면 각 칼럼의 합을 담은 Series를 반환한다.\n",
    "\n",
    "In[53]: df.sum()\n",
    "Out[51]: \n",
    "one    9.25\n",
    "two   -5.80\n",
    "dtype: float64\n",
    "\n",
    "In[54]: df.sum(axis=1) #axis=1 옵션을 넘기면 각 로우의 합을 반환한다.\n",
    "Out[52]: \n",
    "a    1.40\n",
    "b    2.60\n",
    "c    0.00\n",
    "d   -0.55\n",
    "dtype: float64\n",
    "전체 로우나 칼럼의 값이 NA가 아니라면 계산 과정에서 NA 값은 제외시키고 계산된다. 이는 skipna 옵션을 통해 조정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[55]: df.mean(axis=1, skipna=False)\n",
    "Out[53]: \n",
    "a      NaN\n",
    "b    1.300\n",
    "c      NaN\n",
    "d   -0.275\n",
    "dtype: float64\n",
    "\n",
    "idxmin이나 idxmax 같은 메서드는 최소 혹은 최대 값을 가지고 있는 색인 값 같은 간접 통계를 반환한다.\n",
    "In[59]: df.idxmax()\n",
    "\n",
    "Out[57]: \n",
    "one    b\n",
    "two    d\n",
    "dtype: object\n",
    "In[60]: df.cumsum() # 누산 메서드\n",
    "\n",
    "Out[58]: \n",
    "    one  two\n",
    "a  1.40  NaN\n",
    "b  8.50 -4.5\n",
    "c   NaN  NaN\n",
    "d  9.25 -5.8\n",
    "In[61]: df.describe() # 축소나 누산도 아닌 다른 종류의 메서드로 여러 통계 결과를 만들어 낸다.\n",
    "\n",
    "Out[59]: \n",
    "            one       two\n",
    "count  3.000000  2.000000\n",
    "mean   3.083333 -2.900000\n",
    "std    3.493685  2.262742\n",
    "min    0.750000 -4.500000\n",
    "25%    1.075000 -3.700000\n",
    "50%    1.400000 -2.900000\n",
    "75%    4.250000 -2.100000\n",
    "max    7.100000 -1.300000\n",
    "\n",
    "5.3.1 상관관계와 공분산\n",
    "상관관계와 공분산 같은 요약통계 계산은 인자가 두 벌 필요하다. 야후! 금융사이트에서 구한 주식가격과 시가 총액을 담고 있는 다음 DataFrame에 대해 생각해보자.\n",
    "\n",
    "In[62]: import pandas.io.data as web\n",
    "\n",
    "C:\\Users\\Jusung\\Anaconda2\\lib\\site-packages\\pandas\\io\\data.py:33: FutureWarning: \n",
    "The pandas.io.data module is moved to a separate package (pandas-datareader) and will \n",
    "be removed from pandas in a future version.\n",
    "After installing the pandas-datareader package (https://github.com/pydata/pandas-datareader)\n",
    ", you can change the import ``from pandas.io import data, wb`` to ``\n",
    "from pandas_datareader import data, wb``.\n",
    "  FutureWarning)\n",
    "In[63]: all_data = {}\n",
    "\n",
    "In[64]: for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']:\n",
    "\n",
    "...     all_data[ticker] = web.get_data_yahoo(ticker)\n",
    "\n",
    "...     \n",
    "In[66]: price = DataFrame({tic: data['Adj Close'] for tic, data in all_data.items()})\n",
    "In[67]: volume = DataFrame({tic: data['Volume'] for tic, data in all_data.items()})\n",
    "Future Warning이 뜨지만 (파이썬 2.7버전) 괜찮다. \n",
    "각 주식의 퍼센트 변화율을 계산해보겠다.\n",
    "In[68]: returns = price.pct_change()\n",
    "\n",
    "In[69]: returns.tail()\n",
    "Out[66]: \n",
    "                AAPL      GOOG       IBM      MSFT\n",
    "Date                                              \n",
    "2016-03-31 -0.005203 -0.007435  0.020484  0.003270\n",
    "2016-04-01  0.009175  0.006658  0.007065  0.006156\n",
    "2016-04-04  0.010274 -0.006161 -0.002950 -0.002519\n",
    "2016-04-05 -0.011789 -0.010050 -0.013612 -0.015695\n",
    "2016-04-06  0.010473  0.010694  0.000133  0.010264\n",
    "\n",
    "corr 메서드는 NA가 아니고 정렬된 색인에서 연속하는 두 Series에 대해 상관관계를 계산하고 cov 메서드는 공분산을 계산한다.\n",
    "In[73]: returns.MSFT.corr(returns.IBM)\n",
    "\n",
    "Out[70]: 0.50044758994882854\n",
    "In[74]: returns.MSFT.cov(returns.IBM)\n",
    "\n",
    "Out[71]: 8.9984395351248766e-05\n",
    "\n",
    "반면에 DataFrame에서 corr과 cov메서드는 DataFrame 행렬상에서 상관관계와 공분산을 계산한다.\n",
    "In[75]: returns.corr()\n",
    "\n",
    "Out[72]: \n",
    "          AAPL      GOOG       IBM      MSFT\n",
    "AAPL  1.000000  0.409961  0.393292  0.397760\n",
    "GOOG  0.409961  1.000000  0.399543  0.455731\n",
    "IBM   0.393292  0.399543  1.000000  0.500448\n",
    "MSFT  0.397760  0.455731  0.500448  1.000000\n",
    "In[76]: returns.cov()\n",
    "\n",
    "Out[73]: \n",
    "          AAPL      GOOG       IBM      MSFT\n",
    "AAPL  0.000284  0.000112  0.000081  0.000099\n",
    "GOOG  0.000112  0.000263  0.000079  0.000109\n",
    "IBM   0.000081  0.000079  0.000148  0.000090\n",
    "MSFT  0.000099  0.000109  0.000090  0.000219\n",
    "\n",
    "DataFrame의 corrwith 메서드를 사용하면 다른 Series나 DataFrame과의 상관관계를 계산한다. Series를 넘기면 각 칼럼에 대해 계산한 상관관계를 담고 있는 Series를 반환한다.\n",
    "\n",
    "In[77]: returns.corrwith(returns.IBM)\n",
    "\n",
    "Out[74]: \n",
    "AAPL    0.393292\n",
    "GOOG    0.399543\n",
    "IBM     1.000000\n",
    "MSFT    0.500448\n",
    "dtype: float64\n",
    "\n",
    "DataFrame을 넘기면 맞아 떨어지는 칼럼의 이름에 대한 상관관계를 계산한다. 여기서는 시가 총액의 퍼센트 변화율에 대한 상관관계를 계산해보았다.\n",
    "In[78]: returns.corrwith(volume)\n",
    "\n",
    "Out[75]: \n",
    "AAPL   -0.083129\n",
    "GOOG   -0.003435\n",
    "IBM    -0.200958\n",
    "MSFT   -0.084664\n",
    "dtype: float64\n",
    "axis=1 옵션을 넘기면 각 칼럼에 대한 상관관계와 공분산을 계산한다. 모든 경우 데이터는 상관관계를 계산하기 전에 색인의 이름 순서대로 정렬된다.\n",
    "\n",
    "5.3.2 유일 값, 값, 세기, 멤버십\n",
    "또 다른 종류의 메서드로는 1차원 Series에 담긴 값의 정보를 추출하는 메서드가 있다. 다음 예제를 살펴보자.\n",
    "In[79]: obj = Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])\n",
    "In[80]: uniques = obj.unique()\n",
    "In[81]: uniques\n",
    "Out[78]: array(['c', 'a', 'd', 'b'], dtype=object)\n",
    "\n",
    "유일 값은 정렬된 순서로 반환되지 않지만 필요하다면 uniques.sort()를 이용해서 나중에 정렬 할 수 도 있다. 그리고 value_counts 는 Series에서 도수를 계산하여 반환한다.\n",
    "\n",
    "In[82]: obj.value_counts()\n",
    "\n",
    "Out[79]: \n",
    "c    3\n",
    "a    3\n",
    "b    2\n",
    "d    1\n",
    "dtype: int64\n",
    "\n",
    "value_counts에서 반환하는 Series는 담고 있는 값으로 내림차순 정렬된다. 또한 value_counts 메서드는 pandas의 최상위 메서드로, 어떤 배열이나 순차 자료 구조에서도 사용할 수 있다.\n",
    "\n",
    "마지막으로 isin 메서드는 어떤 값이 Series에 있는지 나타내는 불리언 벡터를 반환하는데, Series나 DataFrame의 칼럼에서 값을 골라내고 싶을 때 유용하게 사용할 수 있다.\n",
    "In[87]: mask = obj.isin(['b', 'c'])\n",
    "\n",
    "In[88]: mask\n",
    "\n",
    "Out[85]: \n",
    "0     True\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "4    False\n",
    "5     True\n",
    "6     True\n",
    "7     True\n",
    "8     True\n",
    "dtype: bool\n",
    "In[89]: obj[mask]\n",
    "\n",
    "Out[86]: \n",
    "0    c\n",
    "5    b\n",
    "6    b\n",
    "7    c\n",
    "8    c\n",
    "dtype: object\n",
    "\n",
    "DataFrame의 여러 로우에 대해 히스토그램을 구해야 하는 경우가 있다. 다음 예제를 보자.\n",
    "\n",
    "In[91]: data = DataFrame({'Qu1' : [1, 3, 4, 3, 4],\n",
    "                  'Qu2' : [2, 3, 1, 2, 3],\n",
    "                  'Qu3' : [1, 5, 2, 4, 4]})\n",
    "data\n",
    "\n",
    "Out[88]: \n",
    "   Qu1  Qu2  Qu3\n",
    "0    1    2    1\n",
    "1    3    3    5\n",
    "2    4    1    2\n",
    "3    3    2    4\n",
    "4    4    3    4\n",
    "\n",
    "그런 경우 DataFrame의 apply 함수에 pandas.value_counts를 넘기면 다음과 같은 결과를 얻을 수 있다. value_counts 메서드의 결과가 DataFrame의 칼럼 크기보다 작을 수 있기 때문에 fillna(0) 함수를 이용해서 비어있는 값은 0으로 채워준다. \n",
    "In[94]: result = data.apply(pd.value_counts).fillna(0)\n",
    "\n",
    "In[95]: result\n",
    "\n",
    "Out[92]: \n",
    "   Qu1  Qu2  Qu3\n",
    "1    1    1    1\n",
    "2    0    2    1\n",
    "3    2    2    0\n",
    "4    2    0    2\n",
    "5    0    0    1\n",
    "\n",
    "5.4 누락된 데이터 처리하기\n",
    "\n",
    "누락된 데이터를 처리하는 일은 데이터 분석 애플리케이션에서 흔히 있는 일이다. pandas의 설계 목표 중 하나는 누락 데이터를 가능한 한 쉽게 처리할 수 있도록 하는 것이다. 예를 들어 앞에서 살펴봤듯이 pandas 객체의 모든 기술통계는 누락된 데이터를 배제하고 처리한다.\n",
    "\n",
    "pandas는 누락된 데이터를 실수든 아니든 모두 NaN(Not a Number)으로 취급한다. 그래서 누락된 값을 쉽게 찾을 수 있게 하는 파수병 역할을 한다.\n",
    "\n",
    "In[96]: string_data = Series(['aardvark', 'artichoke', np.nan, 'avocado'])\n",
    "In[97]: string_data\n",
    "Out[94]: \n",
    "0     aardvark\n",
    "1    artichoke\n",
    "2          NaN\n",
    "3      avocado\n",
    "dtype: object\n",
    "In[98]: string_data.isnull()\n",
    "Out[95]: \n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "dtype: bool\n",
    "파이썬의 내장 None 값 또한 NA 값으로 취급된다.\n",
    "\n",
    "In[99]: string_data[0] = None\n",
    "\n",
    "In[100]: string_data.isnull()\n",
    "\n",
    "Out[97]: \n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "dtype: bool\n",
    "pandas에서 NA 값을 표기하는 것이 최선이라는 주장을 하려는 것은 아니지만 pandas에서 사용하는 방법이 더 간단하고 일관적이다. 성능 면에서도 훌륭하며 NumPy 자료형에는 존재하지 않는 진짜 NA 자료형이나 비트 패턴 위에서 만든 간단한 API를 제공한다. NumPy는 계속 개발 중인 프로젝트이므로 앞으로 변경될 가능성이 있다. \n",
    "\n",
    "5.4.1 누락된 데이터 골라내기\n",
    "누락된 데이터를 골라내는 방법에는 여러 가지가 있는데, 직접 손으로 제거하는 것도 한 방법이지만 dropna를 사용하는 것도 매우 유용한 방법이다 . Series에 대해 dropna 메서드를 적용하면 실제 데이터가 들어있는 색인 값과 데이터를 Series 값으로 반환한다.\n",
    "\n",
    "In[101]: from numpy import nan as NA\n",
    "\n",
    "In[102]: data = Series([1, NA, 3.5, NA, 7])\n",
    "\n",
    "In[103]: data.dropna()\n",
    "\n",
    "Out[100]: \n",
    "0    1.0\n",
    "2    3.5\n",
    "4    7.0\n",
    "dtype: float64\n",
    "\n",
    "불리언 색인을 이용해서 직접 계산하는 것도 물론 가능하다.\n",
    "In[104]: data[data.notnull()]\n",
    "\n",
    "Out[101]: \n",
    "0    1.0\n",
    "2    3.5\n",
    "4    7.0\n",
    "dtype: float64\n",
    "\n",
    "DataFrame 객체의 경우는 조금 복잡한데, 모두 NA인 로우나 칼럼을 제외하든가 하나라도 NA인 값을 포함하고 있는 로우나 칼럼을 제외시킬 수도 있다. dropna는 기본적으로 NA 값이 하나라도 있는 로우는 제외시킨다.\n",
    "\n",
    "In[106]: data = DataFrame([[1., 6.5, 3.], [1., NA, NA],\n",
    "                 [NA, NA, NA], [NA, 6.5, 3.]])\n",
    "\n",
    "In[107]: Cleaned = data.dropna()\n",
    "In[108]: data\n",
    "Out[105]: \n",
    "    0    1   2\n",
    "0   1  6.5   3\n",
    "1   1  NaN NaN\n",
    "2 NaN  NaN NaN\n",
    "3 NaN  6.5   3\n",
    "In[109]: Cleaned\n",
    "Out[106]: \n",
    "   0    1  2\n",
    "0  1  6.5  3\n",
    "\n",
    "how='all' 옵션을 주면 모든 값이 NA인 로우만 제외시킨다.\n",
    "In[110]: data.dropna(how='all')\n",
    "Out[107]: \n",
    "    0    1   2\n",
    "0   1  6.5   3\n",
    "1   1  NaN NaN\n",
    "3 NaN  6.5   3\n",
    "칼럼을 제외시키는 방법은 옵셔내으로 axis=1을 주면 로우를 제외시키는 것과 동일한 방식으로 동작한다.\n",
    "\n",
    "In[118]: data[4] = NA\n",
    "\n",
    "In[119]: data\n",
    "\n",
    "Out[116]: \n",
    "    0    1   2   4\n",
    "0   1  6.5   3 NaN\n",
    "1   1  NaN NaN NaN\n",
    "2 NaN  NaN NaN NaN\n",
    "3 NaN  6.5   3 NaN\n",
    "In[120]: data.dropna(axis=1, how='all')\n",
    "\n",
    "Out[117]: \n",
    "    0    1   2\n",
    "0   1  6.5   3\n",
    "1   1  NaN NaN\n",
    "2 NaN  NaN NaN\n",
    "3 NaN  6.5   3\n",
    "\n",
    "DataFrame의 로우를 제외시키는 방법은 주로 시계열 데이터에 사용되는 경향이 있다. 몇 개 이상의 값이 들어있는 로우만 살펴보고 싶다면 thresh 인자에 원하는 값을 넘기면 된다.\n",
    "df = DataFrame(np.random.randn(7, 3))\n",
    "In[123]: df\n",
    "\n",
    "Out[120]: \n",
    "          0         1         2\n",
    "0  0.674988       NaN       NaN\n",
    "1  0.206816       NaN       NaN\n",
    "2  1.890366       NaN       NaN\n",
    "3  1.207395       NaN  0.513191\n",
    "4 -1.933233       NaN  1.315672\n",
    "5 -0.743783  0.009746  0.478140\n",
    "6  0.945863  0.781102 -1.704737\n",
    "In[124]: df.dropna(thresh=3)\n",
    "\n",
    "Out[121]: \n",
    "          0         1         2\n",
    "5 -0.743783  0.009746  0.478140\n",
    "6  0.945863  0.781102 -1.704737\n",
    "5.4.2 누락된 값 채우기\n",
    "\n",
    "누락된 값을 제외시키지 않고 (잠재적으로 다른 데이터도 함께 버려질 가능성이 있다.) 데이터 상의 '구멍'을 어떻게는 메우고 싶은 경우가 있는데, 이런 경우에는 fillna 메서드를 활용하면 된다. 즉, fillna 메서드에 채워 넣고 싶은 값을 넘겨주면 된다.\n",
    "In[127]: df.fillna(0)\n",
    "\n",
    "Out[124]: \n",
    "          0         1         2\n",
    "0  0.674988  0.000000  0.000000\n",
    "1  0.206816  0.000000  0.000000\n",
    "2  1.890366  0.000000  0.000000\n",
    "3  1.207395  0.000000  0.513191\n",
    "4 -1.933233  0.000000  1.315672\n",
    "5 -0.743783  0.009746  0.478140\n",
    "6  0.945863  0.781102 -1.704737\n",
    "fillna에 사전 값을 넘겨서 각 칼럼마다 다른 값을 채워 넣을 수도 있다.\n",
    "In[128]: df.fillna({1: 0.5, 3: -1})\n",
    "\n",
    "Out[125]: \n",
    "          0         1         2\n",
    "0  0.674988  0.500000       NaN\n",
    "1  0.206816  0.500000       NaN\n",
    "2  1.890366  0.500000       NaN\n",
    "3  1.207395  0.500000  0.513191\n",
    "4 -1.933233  0.500000  1.315672\n",
    "5 -0.743783  0.009746  0.478140\n",
    "6  0.945863  0.781102 -1.704737\n",
    "\n",
    "fillna는 새로운 객체를 반환하지만 다음처럼 기존 객체를 변경할 수도 있다.\n",
    "In[131]: _ = df.fillna(0, inplace=True) # _는 이전에 다루던 객체를 의미\n",
    "\n",
    "In[132]: df\n",
    "\n",
    "Out[129]: \n",
    "          0         1         2\n",
    "0  0.674988  0.000000  0.000000\n",
    "1  0.206816  0.000000  0.000000\n",
    "2  1.890366  0.000000  0.000000\n",
    "3  1.207395  0.000000  0.513191\n",
    "4 -1.933233  0.000000  1.315672\n",
    "5 -0.743783  0.009746  0.478140\n",
    "6  0.945863  0.781102 -1.704737\n",
    "재색인에서 사용 가능한 보간 메서드는 fillna 메서드에서도 사용이 가능하다.\n",
    "\n",
    "In[133]: df = DataFrame(np.random.randn(6,3))\n",
    "\n",
    "In[134]: df.ix[2:, 1] = NA; df.ix[4:, 2] = NA\n",
    "\n",
    "In[135]: df\n",
    "\n",
    "Out[132]: \n",
    "          0         1         2\n",
    "0  2.321233  0.243797 -0.049593\n",
    "1 -0.768766 -0.639125 -0.522648\n",
    "2  0.580564       NaN  0.334274\n",
    "3  0.757897       NaN -0.482256\n",
    "4  0.122206       NaN       NaN\n",
    "5  1.561499       NaN       NaN\n",
    "In[136]: df.fillna(method='ffill')\n",
    "\n",
    "Out[133]: \n",
    "          0         1         2\n",
    "0  2.321233  0.243797 -0.049593\n",
    "1 -0.768766 -0.639125 -0.522648\n",
    "2  0.580564 -0.639125  0.334274\n",
    "3  0.757897 -0.639125 -0.482256\n",
    "4  0.122206 -0.639125 -0.482256\n",
    "5  1.561499 -0.639125 -0.482256\n",
    "In[137]: df.fillna(method='ffill', limit = 2) #두 개까지만 채운다. 남용금지?\n",
    "\n",
    "Out[134]: \n",
    "          0         1         2\n",
    "0  2.321233  0.243797 -0.049593\n",
    "1 -0.768766 -0.639125 -0.522648\n",
    "2  0.580564 -0.639125  0.334274\n",
    "3  0.757897 -0.639125 -0.482256\n",
    "4  0.122206       NaN -0.482256\n",
    "5  1.561499       NaN -0.482256\n",
    "\n",
    "조금만 창의적으로 생각하면 fillna를 이용해서 매우 다양한 일을 할 수 있는데, 예를 들면 Series의 평균 값이나 중간 값을 전달할 수도 있다.\n",
    "In[138]: data = Series([1., NA, 3.5, NA, 7])\n",
    "\n",
    "In[139]: data.fillna(data.mean())\n",
    "\n",
    "Out[136]: \n",
    "0    1.000000\n",
    "1    3.833333\n",
    "2    3.500000\n",
    "3    3.833333\n",
    "4    7.000000\n",
    "dtype: float64\n",
    "5.5 계층적 색인\n",
    "\n",
    "계층적 색인은 pandas의 중요한 기능으로, 축에 대해 다중 색인 단계를 지정할 수 있도록 해준다. 약간 추상적으로 말하면 ㅏ원이 높은 데이터를 낮은 차원의 형식으로 다룰 수 있게 해주는 기능이다. 간단한 예제를 하나 살펴보자. 우선 리스트를 담고 있는 리스트나 배열을 가진 Series하나를 생성하자.\n",
    "\n",
    "In[140]: data = Series(np.random.randn(10),\n",
    "              index=[['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'd','d'],\n",
    "                     [1, 2, 3, 1, 2, 3, 1, 2, 2, 3]])\n",
    "\n",
    "In[141]: data\n",
    "\n",
    "Out[138]: \n",
    "a  1    0.750448\n",
    "   2   -0.823054\n",
    "   3    0.562675\n",
    "b  1   -0.629406\n",
    "   2   -1.099839\n",
    "   3    1.614658\n",
    "c  1   -1.297442\n",
    "   2    0.232058\n",
    "d  2   -0.753372\n",
    "   3   -0.176555\n",
    "dtype: float64\n",
    "\n",
    "지금 생성한 객체는 MultiIndex를 색인으로 하는 Series로, 색인의 계층을 보여주고 있다. 바로 위 단계의 색인을 이용해서 하위 계층을 직접 접근할 수 있다.\n",
    "\n",
    "In[142]: data.index\n",
    "\n",
    "Out[139]: \n",
    "MultiIndex(levels=[[u'a', u'b', u'c', u'd'], [1, 2, 3]],\n",
    "           labels=[[0, 0, 0, 1, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 1, 2, 0, 1, 1, 2]])\n",
    "\n",
    "계층적으로 색인된 객체는 데이터의 부분집합을 부분적 색인으로 접근 하는 것이 가능하다.\n",
    "In[143]: data['b']\n",
    "\n",
    "Out[140]: \n",
    "1   -0.629406\n",
    "2   -1.099839\n",
    "3    1.614658\n",
    "dtype: float64\n",
    "In[144]: data['b':'c']\n",
    "\n",
    "Out[141]: \n",
    "b  1   -0.629406\n",
    "   2   -1.099839\n",
    "   3    1.614658\n",
    "c  1   -1.297442\n",
    "   2    0.232058\n",
    "dtype: float64\n",
    "In[145]: data.ix[['b', 'd']]\n",
    "\n",
    "Out[142]: \n",
    "b  1   -0.629406\n",
    "   2   -1.099839\n",
    "   3    1.614658\n",
    "d  2   -0.753372\n",
    "   3   -0.176555\n",
    "dtype: float64\n",
    "\n",
    "하위 계층의 객체를 선택하는 것도 가능하다.\n",
    "\n",
    "In[146]: data[:, 2]\n",
    "\n",
    "Out[143]: \n",
    "a   -0.823054\n",
    "b   -1.099839\n",
    "c    0.232058\n",
    "d   -0.753372\n",
    "dtype: float64\n",
    "\n",
    "계층적인 색인은 데이터를 재형성하고 피벗 테이블 생성 같은 그룹 기반의 작업을 할 때 중요하게 사용된다. 예를 들어 위에서 만든 DataFrame 객체에 unstack 메서드를 사용해서 데이터를 새롭게 배열할 수 도 있다.\n",
    "In[147]: data.unstack()\n",
    "\n",
    "Out[144]: \n",
    "          1         2         3\n",
    "a  0.750448 -0.823054  0.562675\n",
    "b -0.629406 -1.099839  1.614658\n",
    "c -1.297442  0.232058       NaN\n",
    "d       NaN -0.753372 -0.176555\n",
    "In[148]: data.unstack().stack()\n",
    "\n",
    "Out[145]: \n",
    "a  1    0.750448\n",
    "   2   -0.823054\n",
    "   3    0.562675\n",
    "b  1   -0.629406\n",
    "   2   -1.099839\n",
    "   3    1.614658\n",
    "c  1   -1.297442\n",
    "   2    0.232058\n",
    "d  2   -0.753372\n",
    "   3   -0.176555\n",
    "dtype: float64\n",
    "\n",
    "unstack의 반대되는 작업은 stack메서드로 수행한다.\n",
    "\n",
    "stack과 unstack 메서드는 7장에서 더 자세히 알아보기로 하자.\n",
    "\n",
    "DataFrame에서는 두 축 모두 계층적 색인을 가질 수 있다.\n",
    "\n",
    "In[149]: frame = DataFrame(np.arange(12).reshape((4,3)),\n",
    "                  index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                  columns=[['ohio', 'Ohio', 'Colorado',],\n",
    "                           ['Green', 'Red', 'Green']])\n",
    "\n",
    "In[150]: frame\n",
    "\n",
    "Out[147]: \n",
    "     ohio Ohio Colorado\n",
    "    Green  Red    Green\n",
    "a 1     0    1        2\n",
    "  2     3    4        5\n",
    "b 1     6    7        8\n",
    "  2     9   10       11\n",
    "\n",
    "계층적 색인의 각 단계는 이름(문자열이나 어떤 파이썬 객체라도 가능하다)을 가질 수 있고, 만약 이름이 있다면 콘솔 출력 시에 함께 나타난다. ( 색인의 이름과 축의 라벨을 혼동하지 말자!).\n",
    "\n",
    "In[151]: frame.index.names = ['key1', 'key2']\n",
    "\n",
    "In[152]: frame.columns.names = ['state', 'color']\n",
    "\n",
    "In[153]: frame\n",
    "\n",
    "Out[150]: \n",
    "state      ohio Ohio Colorado\n",
    "color     Green  Red    Green\n",
    "key1 key2                    \n",
    "a    1        0    1        2\n",
    "     2        3    4        5\n",
    "b    1        6    7        8\n",
    "     2        9   10       11\n",
    "\n",
    "칼럼의 부분집합을 부분적 색인으로 접근하는 것도 로우에 대한 부분적 색인과 비슷하게 사용하면 된다.\n",
    "\n",
    "In[154]: frame['Ohio']\n",
    "\n",
    "Out[151]: \n",
    "color      Red\n",
    "key1 key2     \n",
    "a    1       1\n",
    "     2       4\n",
    "b    1       7\n",
    "     2      10\n",
    "MultiIndex는 따로 생성한 다음에 재사용이 가능하다. 위에서 살펴본 DataFrame의 칼럼 계층의 이름은 다음처럼 생성할 수 있다.\n",
    "\n",
    "In[162]: pd.MultiIndex.from_arrays([['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']],\n",
    "                       names=['state', 'color'])\n",
    "\n",
    "Out[159]: \n",
    "MultiIndex(levels=[[u'Colorado', u'Ohio'], [u'Green', u'Red']],\n",
    "           labels=[[1, 1, 0], [0, 1, 0]],\n",
    "           names=[u'state', u'color'])\n",
    "5.5.1 계층 순서 바꾸고 정렬하기 \n",
    "계층적 색인에서 계층 순서를 바꾸거나 지정된 계층에 따라 데이터를 정렬해야 하는 경우도 있다. swaplevel은 넘겨받은 2개의 계층 버호나 이름이 뒤바뀐 새로운 객체를 반환한다(하지만 데이터는 변경되지 않는다.)\n",
    "\n",
    "In[164]: frame.swaplevel('key1', 'key2')\n",
    "\n",
    "Out[161]: \n",
    "state      ohio Ohio Colorado\n",
    "color     Green  Red    Green\n",
    "key2 key1                    \n",
    "1    a        0    1        2\n",
    "2    a        3    4        5\n",
    "1    b        6    7        8\n",
    "2    b        9   10       11\n",
    "\n",
    "반면에 sortlevel 메서드는 단일 계층에 속한 데이터를 정렬한다. swaplevel을 사용해서 계층을 바꿀 때 대개는 sortlevel을 사용해서 결과도 사전식으로 정렬한다.\n",
    "\n",
    "In[165]: frame.sortlevel(1)\n",
    "\n",
    "Out[162]: \n",
    "state      ohio Ohio Colorado\n",
    "color     Green  Red    Green\n",
    "key1 key2                    \n",
    "a    1        0    1        2\n",
    "b    1        6    7        8\n",
    "a    2        3    4        5\n",
    "b    2        9   10       11\n",
    "In[166]: frame.swaplevel(0, 1).sortlevel(0)\n",
    "\n",
    "Out[163]: \n",
    "state      ohio Ohio Colorado\n",
    "color     Green  Red    Green\n",
    "key2 key1                    \n",
    "1    a        0    1        2\n",
    "     b        6    7        8\n",
    "2    a        3    4        5\n",
    "     b        9   10       11\n",
    "5.5.2 단계별 요약통계\n",
    "DataFrame과 Series의 많은 기술통계와 요약통계는 level 옵션을 가지고 있는데, 이는 어떤 한 축에 대해 합을 구하고 싶은 단계를 지정할 수 있는 옵션이다. 앞에서 살펴본 DataFrame에서 로우나 칼럼을 아래처럼 단계별로 정렬하여 합을 구할 수 잇다.\n",
    "\n",
    "In[167]: frame.sum(level = 'key2')\n",
    "\n",
    "Out[164]: \n",
    "state  ohio Ohio Colorado\n",
    "color Green  Red    Green\n",
    "key2                     \n",
    "1         6    8       10\n",
    "2        12   14       16\n",
    "\n",
    "In[168]: frame.sum(level='color', axis=1)\n",
    "\n",
    "Out[165]: \n",
    "color      Green  Red\n",
    "key1 key2            \n",
    "a    1         2    1\n",
    "     2         8    4\n",
    "b    1        14    7\n",
    "     2        20   10\n",
    "내부적으로는 pandas의 groupby기능을 이용해서 구현되었는데 자세한 내용은 앞으로 더 살펴 보겠다.\n",
    "\n",
    "5.5.3 DataFrame의 칼럼 사용하기\n",
    "\n",
    "DataFrame에서 로우를 선택하기 위한 색인으로 하나 이상의 칼럼을 사용하는 것은 드물지 않은 일이다. 아니면 로우의 색인을 DataFrame의 칼럼으로 옮기고 싶을 것이다. 다음과 같은 DataFrame이 있다.\n",
    "\n",
    "In[169]: frame = DataFrame({'a': range(7), 'b':range(7, 0, -1),\n",
    "                   'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'],\n",
    "                   'd': [0,1, 2, 0, 1, 2, 3]})\n",
    "\n",
    "In[170]: frame\n",
    "\n",
    "Out[167]: \n",
    "   a  b    c  d\n",
    "0  0  7  one  0\n",
    "1  1  6  one  1\n",
    "2  2  5  one  2\n",
    "3  3  4  two  0\n",
    "4  4  3  two  1\n",
    "5  5  2  two  2\n",
    "6  6  1  two  3\n",
    "DataFrame의 set_index 함수는 하나 이상의 칼럼을 색인으로 하는 새로운 DataFrame을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[171]: frame2 = frame.set_index(['c', 'd'])\n",
    "\n",
    "In[172]: frame2\n",
    "\n",
    "Out[169]: \n",
    "       a  b\n",
    "c   d      \n",
    "one 0  0  7\n",
    "    1  1  6\n",
    "    2  2  5\n",
    "two 0  3  4\n",
    "    1  4  3\n",
    "    2  5  2\n",
    "    3  6  1\n",
    "다음처럼 칼럼을 명시적으로 남겨두지 않으면 DataFrame에서 삭제된다.\n",
    "\n",
    "In[173]: frame.set_index(['c', 'd'], drop=False)\n",
    "\n",
    "Out[170]: \n",
    "       a  b    c  d\n",
    "c   d              \n",
    "one 0  0  7  one  0\n",
    "    1  1  6  one  1\n",
    "    2  2  5  one  2\n",
    "two 0  3  4  two  0\n",
    "    1  4  3  two  1\n",
    "    2  5  2  two  2\n",
    "    3  6  1  two  3\n",
    "\n",
    "반면에 reset_index 함수는 set_index와 반대되는 개념으로, 계층적 색인 단계가 칼럼으로 이동한다.\n",
    "In[174]: frame2.reset_index()\n",
    "\n",
    "Out[171]: \n",
    "     c  d  a  b\n",
    "0  one  0  0  7\n",
    "1  one  1  1  6\n",
    "2  one  2  2  5\n",
    "3  two  0  3  4\n",
    "4  two  1  4  3\n",
    "5  two  2  5  2\n",
    "6  two  3  6  1\n",
    "5.6 pandas와 관련된 기타 주제\n",
    "\n",
    "지금부터는 pandas의 부수적인 내용에 대해서 알아보자.\n",
    "\n",
    "5.6.1 정수 색인\n",
    "pandas 객체를 정수로 색인해서 사용하는 일은 파이썬에서 리스트나 튜플 같은 기본 자료 구조에서 사용되는 색인의 의미와 약간 달라서 초보자들은 종종 실수를 한다.\n",
    "\n",
    "In[175]: ser = Series(np.arange(3.))\n",
    "ser[-1]\n",
    "# 난리가남\n",
    "\n",
    "이때 pandas는 정수 색인에 대한 '대비책'을 세울 수 있지만 알아내기 쉽지 않은 버그가 생기지 않을 만한 안전하고 일반적인 방법은 내가 알기론 없다. 여기 ser 객체는 0, 1, 2 색인을 가지고 있지만 사용자가 원하는 것이 위치 색인인지 이름 색인인지 알아 맞히는 것은 어려운 일이다.\n",
    "In[177]: ser\n",
    "\n",
    "Out[174]: \n",
    "0    0\n",
    "1    1\n",
    "2    2\n",
    "dtype: float64\n",
    "반면에 정수 색인이 아니라면 그리 어렵지는 않다.\n",
    "\n",
    "In[178]: ser2 = Series(np.arange(3.), index=['a', 'b', 'c'])\n",
    "\n",
    "In[179]: ser2[-1]\n",
    "\n",
    "Out[176]: 2.0\n",
    "일관성을 유지하기 위해 색인 값을 가진 축 색인이 있을 경우 정수 데이터는 항상 이름을 지향한다. 이는 ix 슬라이스에도 마찬가지로 적용된다.\n",
    "In[180]: ser.ix[:1]\n",
    "\n",
    "Out[177]: \n",
    "0    0\n",
    "1    1\n",
    "dtype: float64\n",
    "\n",
    "만일 색인의 종류에 상관없이 위치 기반의 색인이 필요하다면 Series의 iget_value 메서드와 DataFrame의 irow, icol 메서드를 사용하면 된다.\n",
    "\n",
    "In[183]: frame = DataFrame((np.arange(6).reshape(3, 2)), index=[2, 0, 1])\n",
    "\n",
    "In[184]: frame.iloc[0]\n",
    "\n",
    "Out[181]: \n",
    "0    0\n",
    "1    1\n",
    "Name: 2, dtype: int32\n",
    "\n",
    "5.6.2 Panel 데이터\n",
    "이 책에서 중요하게 다룰 주제는 아니지만 pandas에는 Panel 이라고 하는 자료 구조가 있는데, Panel은 DataFrame의 3차원 버전이라고 이해하면 된다.\n",
    "\n",
    "형식의 데이터를 다루는 데 초점을 맞추고 있고 계층적 색인을 이용하면 대개의 경우 N차원 배열은 불필요하다.\n",
    "\n",
    "Panel은 DataFrame 객체를 담고 있는 사전이나 3차원 ndarray를 통해 생성할 수 있다. \n",
    "\n",
    "import pandas.io.data as web\n",
    "\n",
    "pdata = pd.Panel(dict((stk, web.get_data_yahoo(stk)) for stk in ['AAPL', 'GOOG', 'MSFT', \n",
    "'DELL']))\n",
    "Panel의 각 항목( DataFrame에서 칼럼이라고 생각하면 된다)은 DataFrame이다.\n",
    "\n",
    "In[187]: pdata\n",
    "\n",
    "Out[184]: \n",
    "<class 'pandas.core.panel.Panel'>\n",
    "Dimensions: 4 (items) x 1595 (major_axis) x 6 (minor_axis)\n",
    "Items axis: AAPL to MSFT\n",
    "Major_axis axis: 2010-01-04 00:00:00 to 2016-04-06 00:00:00\n",
    "Minor_axis axis: Open to Adj Close\n",
    "In[188]: pdata = pdata.swapaxes('items', 'minor')\n",
    "\n",
    "In[189]: pdata['Adj Close']\n",
    "\n",
    "Out[186]: \n",
    "                  AAPL      DELL        GOOG       MSFT\n",
    "Date                                                   \n",
    "2010-01-04   28.313195  14.06528  313.062468  26.227603\n",
    "2010-01-05   28.362145  14.38450  311.683844  26.236076\n",
    "2010-01-06   27.911008  14.10397  303.826685  26.075067\n",
    "2010-01-07   27.859412  14.23940  296.753749  25.803894\n",
    "2010-01-08   28.044630  14.36516  300.709808  25.981851\n",
    "2010-01-11   27.797232  14.37483  300.255255  25.651358\n",
    "2010-01-12   27.481038  14.56830  294.945572  25.481874\n",
    "2010-01-13   27.868673  14.57797  293.252243  25.719151\n",
    "2010-01-14   27.707269  14.22005  294.630868  26.236076\n",
    "2010-01-15   27.244224  13.92985  289.710772  26.151335\n",
    "2010-01-19   28.449462  14.32646  293.516976  26.354715\n",
    "2010-01-20   28.011555  14.03626  289.915587  25.922532\n",
    "2010-01-21   27.527342  13.92017  291.199286  25.431029\n",
    "2010-01-22   26.162022  13.18982  274.730736  24.541239\n",
    "2010-01-25   26.865850  13.43650  269.730740  24.846310\n",
    "2010-01-26   27.245547  13.13662  270.939526  24.998845\n",
    "2010-01-27   27.502206  13.08825  270.779695  25.142907\n",
    "2010-01-28   26.365761  12.84641  266.878565  24.710723\n",
    "2010-01-29   25.409244  12.47882  264.705742  23.880253\n",
    "2010-02-01   25.762481  12.78837  266.244198  24.075159\n",
    "2010-02-02   25.911978  12.86576  265.295156  24.117529\n",
    "2010-02-03   26.357823  12.92380  270.140309  24.261591\n",
    "2010-02-04   25.407921  12.58523  263.127321  23.592131\n",
    "2010-02-05   25.859059  12.80772  265.380075  23.744666\n",
    "2010-02-08   25.681779  12.95282  266.468996  23.490440\n",
    "2010-02-09   25.955637  13.10760  267.952522  23.736192\n",
    "2010-02-10   25.814078  13.30107  266.958496  23.719243\n",
    "2010-02-11   26.283736  13.49454  267.932539  23.829409\n",
    "2010-02-12   26.509966  13.38813  266.294170  23.668399\n",
    "2010-02-16   26.909508  13.67834  270.380071  24.136659\n",
    "               ...       ...         ...        ...\n",
    "2016-02-24   96.099998       NaN  699.559998  51.360001\n",
    "2016-02-25   96.760002       NaN  705.750000  52.099998\n",
    "2016-02-26   96.910004       NaN  705.070007  51.299999\n",
    "2016-02-29   96.690002       NaN  697.770020  50.880001\n",
    "2016-03-01  100.529999       NaN  718.809998  52.580002\n",
    "2016-03-02  100.750000       NaN  718.849976  52.950001\n",
    "2016-03-03  101.500000       NaN  712.419983  52.349998\n",
    "2016-03-04  103.010002       NaN  710.890015  52.029999\n",
    "2016-03-07  101.870003       NaN  695.159973  51.029999\n",
    "2016-03-08  101.029999       NaN  693.969971  51.650002\n",
    "2016-03-09  101.120003       NaN  705.239990  52.840000\n",
    "2016-03-10  101.169998       NaN  712.820007  52.049999\n",
    "2016-03-11  102.260002       NaN  726.820007  53.070000\n",
    "2016-03-14  102.519997       NaN  730.489990  53.169998\n",
    "2016-03-15  104.580002       NaN  728.330017  53.590000\n",
    "2016-03-16  105.970001       NaN  736.090027  54.349998\n",
    "2016-03-17  105.800003       NaN  737.780029  54.660000\n",
    "2016-03-18  105.919998       NaN  737.599976  53.490002\n",
    "2016-03-21  105.910004       NaN  742.090027  53.860001\n",
    "2016-03-22  106.720001       NaN  740.750000  54.070000\n",
    "2016-03-23  106.129997       NaN  738.059998  53.970001\n",
    "2016-03-24  105.669998       NaN  735.299988  54.209999\n",
    "2016-03-28  105.190002       NaN  733.530029  53.540001\n",
    "2016-03-29  107.680000       NaN  744.770020  54.709999\n",
    "2016-03-30  109.559998       NaN  750.530029  55.049999\n",
    "2016-03-31  108.989998       NaN  744.950012  55.230000\n",
    "2016-04-01  109.989998       NaN  749.909973  55.570000\n",
    "2016-04-04  111.120003       NaN  745.289978  55.430000\n",
    "2016-04-05  109.809998       NaN  737.799988  54.560001\n",
    "2016-04-06  110.959999       NaN  745.690002  55.119999\n",
    "\n",
    "[1595 rows x 4 columns]\n",
    "ix를 이용한 라벨 색인을 통한 접근은 3차원에도 일반화되어 특정 날짜나 어떤 기간 동안의 모든 데이터를 다음처럼 선택 할 수 있다.\n",
    "\n",
    "\n",
    "In[190]: pdata.ix[:, '6/1/2012', :]\n",
    "\n",
    "Out[187]: \n",
    "            Open        High         Low       Close     Volume   Adj Close\n",
    "AAPL  569.159996  572.650009  560.520012  560.989983  130246900   74.218116\n",
    "DELL   12.150000   12.300000   12.045000   12.070000   19397600   11.675920\n",
    "GOOG  571.790972  572.650996  568.350996  570.981000    6138700  285.205295\n",
    "MSFT   28.760000   28.959999   28.440001   28.450001   56634300   25.598227\n",
    "In[191]: pdata.ix['Adj Close', '5/22/2012':, :]\n",
    "\n",
    "Out[188]: \n",
    "                  AAPL      DELL        GOOG       MSFT\n",
    "Date                                                   \n",
    "2012-05-22   73.686282  14.58765  300.100412  26.776915\n",
    "2012-05-23   75.484211  12.08221  304.426106  26.192070\n",
    "2012-05-24   74.790973  12.04351  301.528978  26.156079\n",
    "2012-05-25   74.390105  12.05319  295.470050  26.147081\n",
    "2012-05-28         NaN  12.05319         NaN        NaN\n",
    "2012-05-29   75.710442  12.24666  296.873645  26.596962\n",
    "2012-05-30   76.623304  12.14992  293.821674  26.399015\n",
    "2012-05-31   76.432797  11.92743  290.140354  26.264051\n",
    "2012-06-01   74.218116  11.67592  285.205295  25.598227\n",
    "2012-06-04   74.654700  11.60821  289.006480  25.688202\n",
    "2012-06-05   74.461551  11.76298  284.920579  25.652212\n",
    "2012-06-06   75.603286  11.81619  289.995487  26.408013\n",
    "2012-06-07   75.637681  11.73396  288.826666  26.300040\n",
    "2012-06-08   76.775446  11.72429  289.935570  26.677940\n",
    "2012-06-11   75.564914  11.47278  283.966519  26.003119\n",
    "2012-06-12   76.225086  11.57919  282.268201  26.354027\n",
    "2012-06-13   75.695894  11.87423  280.265216  26.210064\n",
    "2012-06-14   75.612542  11.93711  279.246220  26.399015\n",
    "2012-06-15   75.956519  11.89841  281.973510  27.010853\n",
    "2012-06-18   77.497794  12.01449  285.140358  26.848896\n",
    "2012-06-19   77.713448  11.78233  290.475012  27.622691\n",
    "2012-06-20   77.492502  11.89841  288.467038  27.829636\n",
    "2012-06-21   76.424856  11.60821  282.323161  27.118824\n",
    "2012-06-22   77.010939  11.80168  285.455033  27.622691\n",
    "2012-06-25   75.512000  11.55500  280.070407  26.875889\n",
    "2012-06-26   75.678696  11.53565  282.058429  27.010853\n",
    "2012-06-27   76.005469  11.92743  284.366112  27.145817\n",
    "2012-06-28   75.284441  11.55984  281.873596  26.911879\n",
    "2012-06-29   77.262308  12.10155  289.745749  27.523717\n",
    "2012-07-02   78.389489  11.98064  289.945546  27.496724\n",
    "               ...       ...         ...        ...\n",
    "2016-02-24   96.099998       NaN  699.559998  51.360001\n",
    "2016-02-25   96.760002       NaN  705.750000  52.099998\n",
    "2016-02-26   96.910004       NaN  705.070007  51.299999\n",
    "2016-02-29   96.690002       NaN  697.770020  50.880001\n",
    "2016-03-01  100.529999       NaN  718.809998  52.580002\n",
    "2016-03-02  100.750000       NaN  718.849976  52.950001\n",
    "2016-03-03  101.500000       NaN  712.419983  52.349998\n",
    "2016-03-04  103.010002       NaN  710.890015  52.029999\n",
    "2016-03-07  101.870003       NaN  695.159973  51.029999\n",
    "2016-03-08  101.029999       NaN  693.969971  51.650002\n",
    "2016-03-09  101.120003       NaN  705.239990  52.840000\n",
    "2016-03-10  101.169998       NaN  712.820007  52.049999\n",
    "2016-03-11  102.260002       NaN  726.820007  53.070000\n",
    "2016-03-14  102.519997       NaN  730.489990  53.169998\n",
    "2016-03-15  104.580002       NaN  728.330017  53.590000\n",
    "2016-03-16  105.970001       NaN  736.090027  54.349998\n",
    "2016-03-17  105.800003       NaN  737.780029  54.660000\n",
    "2016-03-18  105.919998       NaN  737.599976  53.490002\n",
    "2016-03-21  105.910004       NaN  742.090027  53.860001\n",
    "2016-03-22  106.720001       NaN  740.750000  54.070000\n",
    "2016-03-23  106.129997       NaN  738.059998  53.970001\n",
    "2016-03-24  105.669998       NaN  735.299988  54.209999\n",
    "2016-03-28  105.190002       NaN  733.530029  53.540001\n",
    "2016-03-29  107.680000       NaN  744.770020  54.709999\n",
    "2016-03-30  109.559998       NaN  750.530029  55.049999\n",
    "2016-03-31  108.989998       NaN  744.950012  55.230000\n",
    "2016-04-01  109.989998       NaN  749.909973  55.570000\n",
    "2016-04-04  111.120003       NaN  745.289978  55.430000\n",
    "2016-04-05  109.809998       NaN  737.799988  54.560001\n",
    "2016-04-06  110.959999       NaN  745.690002  55.119999\n",
    "\n",
    "[988 rows x 4 columns]\n",
    "\n",
    "통계 모델에 알맞게 Panel 데이터를 출력하는 다른 방법은 DataFrame을 쌓아 놓는 것이다.\n",
    "\n",
    "... stacked = pdata.ix[:, '5/30/2012':, :].to_frame()\n",
    "\n",
    "In[193]: stacked\n",
    "\n",
    "Out[190]: \n",
    "                        Open        High         Low       Close     Volume  \\\n",
    "Date       minor                                                              \n",
    "2012-05-30 AAPL   569.199997  579.989990  566.559990  579.169998  132357400   \n",
    "           DELL    12.590000   12.700000   12.460000   12.560000   19787800   \n",
    "           GOOG   588.161028  591.901014  583.530999  588.230992    3827600   \n",
    "           MSFT    29.350000   29.480000   29.120001   29.340000   41585500   \n",
    "2012-05-31 AAPL   580.740021  581.499985  571.460022  577.730019  122918600   \n",
    "           DELL    12.530000   12.540000   12.330000   12.330000   19955600   \n",
    "           GOOG   588.720982  590.001032  579.001013  580.860990    5958800   \n",
    "           MSFT    29.299999   29.420000   28.940001   29.190001   39134000   \n",
    "2012-06-01 AAPL   569.159996  572.650009  560.520012  560.989983  130246900   \n",
    "           DELL    12.150000   12.300000   12.045000   12.070000   19397600   \n",
    "           GOOG   571.790972  572.650996  568.350996  570.981000    6138700   \n",
    "           MSFT    28.760000   28.959999   28.440001   28.450001   56634300   \n",
    "2012-06-04 AAPL   561.500008  567.499985  548.499977  564.289978  139248900   \n",
    "           DELL    12.110000   12.112500   11.800000   12.000000   17015700   \n",
    "           GOOG   570.220958  580.491016  570.011006  578.590973    4883500   \n",
    "           MSFT    28.620001   28.780001   28.320000   28.549999   47926300   \n",
    "2012-06-05 AAPL   561.269989  566.470001  558.330002  562.830025   97053600   \n",
    "           DELL    11.950000   12.240000   11.950000   12.160000   15620900   \n",
    "           GOOG   575.451008  578.131003  566.470986  570.410999    4697200   \n",
    "           MSFT    28.510000   28.750000   28.389999   28.510000   45715400   \n",
    "2012-06-06 AAPL   567.770004  573.849983  565.499992  571.460022  100363900   \n",
    "           DELL    12.210000   12.280000   12.090000   12.215000   20779900   \n",
    "           GOOG   576.480979  581.970971  573.611004  580.570966    4207200   \n",
    "           MSFT    28.879999   29.370001   28.809999   29.350000   46860500   \n",
    "2012-06-07 AAPL   577.290009  577.320023  570.500000  571.720001   94941700   \n",
    "           DELL    12.320000   12.410000   12.120000   12.130000   20074000   \n",
    "           GOOG   587.601014  587.891038  577.251006  578.230986    3530100   \n",
    "           MSFT    29.639999   29.700001   29.170000   29.230000   37792800   \n",
    "2012-06-08 AAPL   571.599998  580.580017  568.999992  580.319984   86879100   \n",
    "           DELL    12.130000   12.225000   12.020000   12.120000   18155600   \n",
    "                     ...         ...         ...         ...        ...   \n",
    "2016-03-23 AAPL   106.480003  107.070000  105.900002  106.129997   25452600   \n",
    "           GOOG   742.359985  745.719971  736.150024  738.059998    1421900   \n",
    "           MSFT    54.110001   54.240002   53.740002   53.970001   19905300   \n",
    "2016-03-24 AAPL   105.470001  106.250000  104.889999  105.669998   25480900   \n",
    "           GOOG   732.010010  737.747009  731.000000  735.299988    1564800   \n",
    "           MSFT    53.840000   54.330002   53.730000   54.209999   18842700   \n",
    "2016-03-28 AAPL   106.000000  106.190002  105.059998  105.190002   19303600   \n",
    "           GOOG   736.789978  738.989990  732.500000  733.530029    1299800   \n",
    "           MSFT    54.209999   54.290001   53.330002   53.540001   16988200   \n",
    "2016-03-29 AAPL   104.889999  107.790001  104.879997  107.680000   30774100   \n",
    "           GOOG   734.590027  747.250000  728.760010  744.770020    1902100   \n",
    "           MSFT    53.660000   54.860001   53.450001   54.709999   23375000   \n",
    "2016-03-30 AAPL   108.650002  110.419998  108.599998  109.559998   45159900   \n",
    "           GOOG   750.099976  757.880005  748.739990  750.530029    1781000   \n",
    "           MSFT    54.930000   55.639999   54.900002   55.049999   22920300   \n",
    "2016-03-31 AAPL   109.720001  109.900002  108.879997  108.989998   25685700   \n",
    "           GOOG   749.250000  750.849976  740.940002  744.950012    1712400   \n",
    "           MSFT    54.950001   55.590000   54.860001   55.230000   26173800   \n",
    "2016-04-01 AAPL   108.779999  110.000000  108.199997  109.989998   25626200   \n",
    "           GOOG   738.599976  750.340027  737.000000  749.909973    1574900   \n",
    "           MSFT    55.049999   55.610001   54.570000   55.570000   24298600   \n",
    "2016-04-04 AAPL   110.419998  112.190002  110.269997  111.120003   37333500   \n",
    "           GOOG   750.059998  752.799988  742.429993  745.289978    1134200   \n",
    "           MSFT    55.430000   55.660000   55.000000   55.430000   18909100   \n",
    "2016-04-05 AAPL   109.510002  110.730003  109.419998  109.809998   26495300   \n",
    "           GOOG   738.000000  742.799988  735.369995  737.799988    1129800   \n",
    "           MSFT    55.189999   55.299999   54.459999   54.560001   19148800   \n",
    "2016-04-06 AAPL   110.230003  110.980003  109.199997  110.959999   26047800   \n",
    "           GOOG   735.770020  746.239990  735.559998  745.690002    1050200   \n",
    "           MSFT    54.360001   55.200001   54.209999   55.119999   21032100   \n",
    "\n",
    "                   Adj Close  \n",
    "Date       minor              \n",
    "2012-05-30 AAPL    76.623304  \n",
    "           DELL    12.149920  \n",
    "           GOOG   293.821674  \n",
    "           MSFT    26.399015  \n",
    "2012-05-31 AAPL    76.432797  \n",
    "           DELL    11.927430  \n",
    "           GOOG   290.140354  \n",
    "           MSFT    26.264051  \n",
    "2012-06-01 AAPL    74.218116  \n",
    "           DELL    11.675920  \n",
    "           GOOG   285.205295  \n",
    "           MSFT    25.598227  \n",
    "2012-06-04 AAPL    74.654700  \n",
    "           DELL    11.608210  \n",
    "           GOOG   289.006480  \n",
    "           MSFT    25.688202  \n",
    "2012-06-05 AAPL    74.461551  \n",
    "           DELL    11.762980  \n",
    "           GOOG   284.920579  \n",
    "           MSFT    25.652212  \n",
    "2012-06-06 AAPL    75.603286  \n",
    "           DELL    11.816190  \n",
    "           GOOG   289.995487  \n",
    "           MSFT    26.408013  \n",
    "2012-06-07 AAPL    75.637681  \n",
    "           DELL    11.733960  \n",
    "           GOOG   288.826666  \n",
    "           MSFT    26.300040  \n",
    "2012-06-08 AAPL    76.775446  \n",
    "           DELL    11.724290  \n",
    "                     ...  \n",
    "2016-03-23 AAPL   106.129997  \n",
    "           GOOG   738.059998  \n",
    "           MSFT    53.970001  \n",
    "2016-03-24 AAPL   105.669998  \n",
    "           GOOG   735.299988  \n",
    "           MSFT    54.209999  \n",
    "2016-03-28 AAPL   105.190002  \n",
    "           GOOG   733.530029  \n",
    "           MSFT    53.540001  \n",
    "2016-03-29 AAPL   107.680000  \n",
    "           GOOG   744.770020  \n",
    "           MSFT    54.709999  \n",
    "2016-03-30 AAPL   109.559998  \n",
    "           GOOG   750.530029  \n",
    "           MSFT    55.049999  \n",
    "2016-03-31 AAPL   108.989998  \n",
    "           GOOG   744.950012  \n",
    "           MSFT    55.230000  \n",
    "2016-04-01 AAPL   109.989998  \n",
    "           GOOG   749.909973  \n",
    "           MSFT    55.570000  \n",
    "2016-04-04 AAPL   111.120003  \n",
    "           GOOG   745.289978  \n",
    "           MSFT    55.430000  \n",
    "2016-04-05 AAPL   109.809998  \n",
    "           GOOG   737.799988  \n",
    "           MSFT    54.560001  \n",
    "2016-04-06 AAPL   110.959999  \n",
    "           GOOG   745.690002  \n",
    "           MSFT    55.119999  \n",
    "\n",
    "[3277 rows x 6 columns]\n",
    "이를 위해 DataFrame에는 to_panel 메서와 그 반대인 to_frame 메서드가 있다.\n",
    "In[195]: stacked.to_panel()\n",
    "\n",
    "Out[192]: \n",
    "<class 'pandas.core.panel.Panel'>\n",
    "Dimensions: 6 (items) x 982 (major_axis) x 4 (minor_axis)\n",
    "Items axis: Open to Adj Close\n",
    "Major_axis axis: 2012-05-30 00:00:00 to 2016-04-06 00:00:00\n",
    "Minor_axis axis: AAPL to MSFT\n",
    "\n",
    " 저작자 표시 신고\n",
    "'Python for data analysis' 카테고리의 다른 글\n",
    "Chapter 5 pandas 시작하기  (0)\t2016.03.25\n",
    "Chapter 4. Numpy 기본 : 배열과 벡터 계산  (0)\t2016.03.11\n",
    "Chapter 3. IPython 소개  (0)\t2016.03.11\n",
    "Chapter 2 사례 소개  (0)\t2016.03.04\n",
    "Chaper 1 시작하기 전에  (0)\t2016.03.04\n",
    "posted by 신퐁\n",
    "0 0\n",
    "2016.03.11 17:45 Python for data analysis\n",
    "Chapter 4. Numpy 기본 : 배열과 벡터 계산\n",
    "Chapter 4. Numpy : 배열과 벡터 계산\n",
    "\n",
    "Numerical Python의 줄임말인 Numpy는 고성능의 과학계산 컴퓨팅과 데이터 분석에 필요한 기본 패키지다. Numpy는 이 책에서 사용하는 거의 모든 종류의 고수준의 도구를 작성하는 데 토대가 되는 패키지로 제공하는 기능은 다음과 같다.\n",
    "\n",
    "-빠르고 메모리를 효율적으로 사용하며 벡터 산술연산과 세련된 브로드캐스팅 기능을 제공하는 다차원 배열인 ndarray\n",
    "-반복문을 작성할 필요 없이 전체 데이터 배열에 대해 빠른 연산을 제공하는 표준 수학 함수\n",
    "-배열 데이터를 디스크에 쓰거나 읽을 수 있는 도구와 메모리에 올려진 파일을 사용하는 도구\n",
    "-선형대수, 난수 발생기, 푸리에 변환 기능\n",
    "-C, C++, 포트란으로 쓰여진 코드를 통합하는 도구\n",
    "\n",
    "마지막 항목은 생태계 관점에서 봤을 때 가장 중요한 기능으로 Numpy는 사용하기 편한 C API를 제공하며 데이터를 다른 저수준 언어로 쓰여진 외부 라이브러리에 쉽게 전달 할 수 있다.\n",
    "또한 외부 라이브러리에서 반환된 데이터를 파이썬의 NumPy 배열 형태로 불러올 수도 있다. \n",
    "\n",
    "NumPy 그 자체로는 고수준의 데이터 분석 기능을 제공하지 않으므로 NumPy 배열과 배열 기반의 컴퓨팅에 대한 이해를 한다면 pandas 같은 도구를 좀 더 효율적으로 사용할 수 있다. \n",
    "\n",
    "대부분 데이터 분석 애플리케이션에서 중요하게 사용되는 기능\n",
    "- 벡터 배열상에서 데이터 개조, 정제, 부분 집합, 필터링, 변형, 다른 종류 연산의 빠른 수행 \n",
    "- 정렬, 유일 원소 찾기, 집합연산 같은 일반적인 배열 처리 알고리즘\n",
    "- 통계의 효과적인 표현과 데이터의 수집/요약\n",
    "- 다른 종류의 데이터 묶음을 병합하고 엮기 위한 데이터 정렬과 데이터 간의 관계 조작\n",
    "- if - elif - else를 포함하는 반복문 대신 사용할 수 있는 조건절을 표현할 수 있는 배열 표현            (comprehension)\n",
    "- 데이터 그룹 전체에 적용할 수 있는 수집, 변형, 함수 적용 같은 데이터 처리.\n",
    "\n",
    "import numpy as np\n",
    "NumPy는 이런 연산을 위한 기본 라이브러리를 제공한다.\n",
    "\n",
    "4.1 NumPy ndarray: 다차원 배열 객체\n",
    "\n",
    "NumPy의 핵심 기능 중 하나는 N차원의 배열 객체 또는 ndarray로 파이썬에서 사용할 수 있는 대규모 데이터 집합을 담을 수 있는 빠르고 유연한 자료 구조다.\n",
    "In[2]: import numpy as np\n",
    "In[3]: data = np.random.randn(2, 3)\n",
    "In[4]: data\n",
    "Out[4]: \n",
    "array([[-0.56285369, -0.06812205,  0.75793005],\n",
    "       [ 0.71350143,  0.114842  , -0.78867801]])\n",
    "In[6]: data * 10\n",
    "Out[6]: \n",
    "array([[-5.62853693, -0.68122054,  7.5793005 ],\n",
    "       [ 7.13501431,  1.14842001, -7.88678008]])\n",
    "In[7]: data + data\n",
    "Out[7]: \n",
    "array([[-1.12570739, -0.13624411,  1.5158601 ],\n",
    "       [ 1.42700286,  0.229684  , -1.57735602]])\n",
    " ndarray는 같은 종류의 데이터를 담을 수 있는 포괄적인 다차원 배열이며, ndarray의 모든 원소는 같은 자료형이어야만 한다.\n",
    "\n",
    "모든 배열은 각 차원의 크기를 알려주는 shape라는 튜플과 배열에 저장된 자료형을 알려주는 dtype라는 객체를 가지고 있다.\n",
    "\n",
    "In[8]: data.shape\n",
    "Out[8]: (2L, 3L)\n",
    "In[9]: data.dtype\n",
    "Out[9]: dtype('float64')\n",
    "이 장에서는 NumPy의 배열을 사용하는 기초 방법에 대해 소개한다.\n",
    "\n",
    "배열 위주 프로그래밍과 생각하는 방법에 능숙해지는 것이 파이썬을 이용한 과학계산의 고수가 되는 지름길이다.\n",
    "\n",
    "4.1.1 ndarray 생성\n",
    "\n",
    "배열을 생성하는 가장 쉬운 방법은 array함수를 이용하는 것이다. 순차적인 객체(다른 배열도 포함하여)를 받아 넘겨받은 데이터가 들어잇는 새로운 NumPy 배열을 생성한다. 예를 들어 파이썬의 리스트는 변환하기 좋은 예다.\n",
    "\n",
    "In[10]: data1 = [6, 7.5, 8, 0, 1]\n",
    "In[11]: arr1 = np.array(data1)\n",
    "In[12]: arr1\n",
    "Out[12]: array([ 6. ,  7.5,  8. ,  0. ,  1. ])\n",
    "같은 길이의 리스트가 담겨있는 순차 데이터는 다차원 배열로 변환이 가능하다.\n",
    "\n",
    "In[23]: data2 = [[1,2,3,4],[5,6,7,8]]\n",
    "In[24]: arr2 = np.array(data2)\n",
    "In[25]: arr2\n",
    "Out[25]: \n",
    "array([[1, 2, 3, 4],\n",
    "       [5, 6, 7, 8]])\n",
    "In[26]: arr2.ndim     \n",
    "Out[26]: 2  \n",
    "In[27]: arr2.shape\n",
    "Out[27]: (2L, 4L)\n",
    "\n",
    "명시적으로 지정하지 않는 한 np.array는 생성될 때 적절한 자료형을 추정한다. 그렇게 추정된 자료형은 dtype 객체에 저장되는데, 먼저 살펴본 예로 들어 보면,\n",
    "In[28]: arr1.dtype\n",
    "Out[28]: dtype('float64')\n",
    "In[29]: arr2.dtype\n",
    "Out[29]: dtype('int32')\n",
    "또한 np.array는 새로운 배열을 생성하기 위한 여러 함수를 가지고 있는데,\n",
    " 예를 들면 zeros와 ones는 주어진 길이나 모양에 각각 0과 1이 들어있는 배열을 생성한다.\n",
    " empty함수는 초기화되지 않은 배열을 생성하는데,\n",
    "이런 메서드를 사용해서 다차원 배열을 생성하려면 원하는 형태의 튜플을 넘기면 된다.\n",
    "\n",
    "In[30]: np.zeros(10)\n",
    "Out[30]: array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
    "In[31]: np.zeros((3, 6))  # 6개의 0으로 구성된 리스트 3개 \n",
    "Out[31]: \n",
    "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
    "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
    "       [ 0.,  0.,  0.,  0.,  0.,  0.]])\n",
    "In[32]: np.empty((2, 3, 2)) '''2개의 초기화되지 않은 값으로 채워진 배열을 가진 리스트\n",
    "  3개를 가진 리스트를 2개 생성 '''\n",
    "Out[32]: \n",
    "array([[[  8.74496193e-322,   0.00000000e+000],\n",
    "        [  0.00000000e+000,   0.00000000e+000],\n",
    "        [  0.00000000e+000,   0.00000000e+000]],\n",
    "\n",
    "       [[  0.00000000e+000,   0.00000000e+000],\n",
    "        [  0.00000000e+000,   0.00000000e+000],\n",
    "        [  0.00000000e+000,   0.00000000e+000]]])\n",
    "arange는 파이썬의 range 함수의 배열 버전이다.\n",
    "In[33]: np.arange(15)\n",
    "Out[33]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n",
    "배열 생성 함수 목록은 page 119 표 4-1 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.2 ndarray의 자료형\n",
    "\n",
    "자료형, dtype은 ndarray가 특정 데이터를 메모리에서 해석하기 위해 필요한 정보를 담고 있는 특수한 객체다.\n",
    "In[34]: arr1 = np.array([1, 2, 3], dtype=np.float64)\n",
    "In[35]: arr2 = np.array([1, 2, 3], dtype=np.int32)\n",
    "In[36]: arr1.dtype\n",
    "Out[36]: dtype('float64')\n",
    "In[37]: arr2.dtype\n",
    "Out[37]: dtype('int32')\n",
    "dtype가 있기에 NumPy가 강력하면서도 유연한 도구가 될 수 있었는데, 대부분의 데이터는 디스크에서 데이터를 읽고 쓰기 편하도록 하위 레벨의 표현에 직접적으로 맞춰져 있으며, C나 포트란 같은 저수준 언어로 작성된 코드와 쉽게 연동이 가능하다. 산술 데이터의 dtype는 float, int 같은 자료형의 이름과 하나의 원소가 차지하는 비트 수로 이루어진다. 파이썬의 float 객체에서 사용되는 표준 배정밀도 부동소수점 값은 8바이트 혹은 64비트로 이루어지는데, 이 자료형은 NumPy에서 float64로 표현된다.\n",
    "\n",
    "NumPy 자료형 목록은 page 120 표 4-2 참조\n",
    "\n",
    "NOTE NumPy의 모든 dtype을 외울 필요는 없다. 주로 사용하게 될 자료형의 일바적인 종류만 신경 쓰면 된다. 주로 대용량 데이터가 메모리나 디스크에 저장되는 방식을 제어해야 할 필요가 있을 때 알아 두면 좋다.\n",
    "\n",
    "ndarray의 astype 메서드를 사용해서 dtype을 다른 형으로 명시적 변경이 가능하다.\n",
    "\n",
    "In[41]: arr = np.array([1, 2, 3, 4, 5])\n",
    "In[42]: arr.dtype \n",
    "Out[42]: dtype('int32')\n",
    "In[43]: float_arr = arr.astype(np.float64) #int32에서 float64로 자료형 변경\n",
    "In[44]: float_arr.dtype # 변경됨을 확인, 정수형을 부동소수점으로 변환하였다. \n",
    "Out[44]: dtype('float64') \n",
    "만약 부동소수점 숫자를 정수형으로 변환하면 소수점 아랫자리는 버려질 것이다.\n",
    "\n",
    "In[45]: arr = np.array([3.7, -1.2, -2.6, 0.5, 12.9, 10.1])\n",
    "In[46]: arr\n",
    "Out[46]: array([  3.7,  -1.2,  -2.6,   0.5,  12.9,  10.1])\n",
    "In[47]: arr.astype(np.int32)\n",
    "Out[47]: array([ 3, -1, -2,  0, 12, 10]) # 소숫점 아랫자리가 버려졌다.\n",
    "숫자 형식의 문자열을 담고 있는 배열이 있다면 astype을 사용하여 숫자로 변환 할 수 있다. \n",
    "\n",
    "In[50]: numeric_strings = np.array(['1.25', '-9.6', '42'], dtype=np.string_) #문자열을 가지고 있는 배열\n",
    "In[51]: numeric_strings.astype(float) #astype명령을 사용해 문자열을 float으로 바꾸어줌, float이라고해도 알아서 바꿔줌\n",
    "Out[51]: array([  1.25,  -9.6 ,  42.  ])\n",
    "int_array = np.arange(10)\n",
    "calibers = np.array([.22, .270, .357, .380, .44, .50], dtype=np.float64)\n",
    "int_array.astype(calibers.dtype) #int_array배열의 자료형을 calibers 배열의 dtype인 float64형태로 맞추어줌 , 결과는 생략\n",
    "4.1.3 배열과 스칼라 간의 연산\n",
    "\n",
    "배열은 for 반복문을 작성하지 않고 데이터를 일괄처리할 수 있기 때문에 중요하다. 이를 벡터화라고 하는데, 같은 크기의 배열 간 산술연산은 배열의 각 요소 단위로 적용된다. (element wise **)\n",
    "In[52]: arr = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "In[53]: arr\n",
    "Out[53]: \n",
    "array([[ 1.,  2.,  3.],\n",
    "       [ 4.,  5.,  6.]])\n",
    "In[54]: arr* arr\n",
    "Out[54]: \n",
    "array([[  1.,   4.,   9.],\n",
    "       [ 16.,  25.,  36.]])\n",
    "In[55]: arr- arr\n",
    "Out[55]: \n",
    "array([[ 0.,  0.,  0.],\n",
    "       [ 0.,  0.,  0.]])\n",
    "스칼라 값에 대한 산술연산은 각 요소로 전달된다.\n",
    "\n",
    "크기가 다른 배열 간의 연산은 브로드캐스팅이라고 한다.\n",
    "이에 대해서는 12장에서 하게 된다.\n",
    "\n",
    "4.1.4 색인과 슬라이싱 기초\n",
    "NumPy 배열 색인에 대해서는 다룰 주제가 많다. 데이터의 부분 집합이나 개별 요소를 선택 하기 위한 수많은 방법이 존재한다. 1차원 배열은 단순하며 표면적으로는 파이썬의 리스트와 유사하게 동작한다.\n",
    "\n",
    "In[56]: arr = np.arange(10) \n",
    "In[57]: arr\n",
    "Out[57]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "In[58]: arr[5] #5번째 수 불러오기\n",
    "Out[58]: 5\n",
    "In[59]: arr[5:8] # 6번째에서부터 8번째까지\n",
    "Out[59]: array([5, 6, 7])\n",
    "In[60]: arr[5:8] = 12  # 6~8번째 수를 12로 치환\n",
    "In[61]: arr\n",
    "Out[61]: array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])\n",
    "이처럼 배열 조각에 스칼라 값을 대입하면 12가 선택 영역 전체로 전파된다. (이후로는 브로드캐스팅이라고 한다.) 리스트와의 중요한 차이점은 배열 조각은 원본 배열의 뷰라는 점이다. \n",
    "즉, 데이터는 복사되지 않고 뷰에 대한 변경은 그대로 원본 배열에 반영된다는 것이다. \n",
    "\n",
    "In[62]: arr_slice = arr[5:8]\n",
    "In[63]: arr_slice[1]\n",
    "Out[63]: 12\n",
    "In[64]: arr_slice[1] = 12345\n",
    "In[65]: arr\n",
    "Out[65]: array([    0,     1,     2,     3,     4,    12, 12345,    12,     8,     9]) \n",
    "# 여기서 보면 arr_slice의 변수에서 슬라이싱하고 조작했던게 arr에도 반영된다. 연동되어있다.\n",
    "NumPy는 대용량 데이터 처리를 염두에 두고 설계되었기 때문에 만약 NumPy가 데이터 복사를 남발한다면 성능과 메모리 문제에 직면할 것이다. \n",
    "\n",
    "NOTE : 만약에 뷰 대신 ndrray 슬라이스의 복사본을 얻고 싶다면 arr[5:8].copy()를 사용해서 명시적으로 배열을 복사하면 된다.\n",
    "\n",
    "다차원 배열을 다루려면 좀 더 많은 옵션이 필요하다. 2차원 배열에서 각 색인에 해당하는 요소는 스칼라 값이 아니라 1차원 배열이 된다.\n",
    "\n",
    "In[66]: arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "In[67]: arr2d[2]\n",
    "Out[67]: array([7, 8, 9])\n",
    "따라서 개별 요소는 재귀적으로 접근해야 한다다음의 두 표현은 같다 하지만 그렇게 하기는 귀찮으니 구분된 색인 리스트를 넘기면 된다. \n",
    "In[68]: arr2d[0][2]\n",
    "Out[68]: 3\n",
    "In[69]: arr2d[0, 2]\n",
    "Out[69]: 3\n",
    "\n",
    "In[73]: arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "In[74]: arr3d\n",
    "Out[74]: \n",
    "array([[[ 1,  2,  3],\n",
    "        [ 4,  5,  6]],\n",
    "\n",
    "       [[ 7,  8,  9],\n",
    "        [10, 11, 12]]])\n",
    "In[75]: arr3d[0]\n",
    "Out[75]: \n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6]])\n",
    "In[76]: old_values = arr3d[0].copy()\n",
    "In[77]: arr3d[0] = 42\n",
    "In[78]: arr3d\n",
    "Out[78]: \n",
    "array([[[42, 42, 42],\n",
    "        [42, 42, 42]],\n",
    "\n",
    "       [[ 7,  8,  9],\n",
    "        [10, 11, 12]]])\n",
    "In[79]: arr3d[0] = old_values\n",
    "In[80]: arr3d\n",
    "Out[80]: \n",
    "array([[[ 1,  2,  3],\n",
    "        [ 4,  5,  6]],\n",
    "\n",
    "       [[ 7,  8,  9],\n",
    "        [10, 11, 12]]])\n",
    "슬라이스 색인\n",
    "\n",
    "파이썬의 리스트 같은 1차원 객체처럼 ndarray는 익숙한 문법으로 슬라이싱할 수 있다.\n",
    "\n",
    "In[87]: arr[1:6]\n",
    "Out[87]: array([ 1,  2,  3,  4, 64])\n",
    "In[88]: arr2d\n",
    "Out[88]: \n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6],\n",
    "       [7, 8, 9]])\n",
    "In[89]: arr2d[:2]\n",
    "Out[89]: \n",
    "array([[1, 2, 3],\n",
    "       [4, 5, 6]])\n",
    "In[90]: arr2d[:2, 1:]\n",
    "Out[90]: \n",
    "array([[2, 3],\n",
    "       [5, 6]])\n",
    "In[91]: arr2d[1, :2]\n",
    "Out[91]: array([4, 5])\n",
    "In[92]: arr2d[2, :1]\n",
    "Out[92]: array([7])\n",
    "\n",
    "물론 슬라이싱 구문에 값을 대입하면 선택 영역 전체에 값이 할당된다.\n",
    "\n",
    "4.1.5 불리언 색인\n",
    "중복된 이름이 포함된 배열이 있다고 하자. 그리고 numpy.random 모듈에 있는 randn 함수를 사용해서 임의의 표준정규분포 데이터를 생성하자.\n",
    "\n",
    "In[93]: names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])\n",
    "In[94]: data = np.random.randn(7, 4) # 4개의 난수를 갖는 리스트를 7개 뱉어라\n",
    "In[95]: names\n",
    "Out[95]: \n",
    "array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'], \n",
    "      dtype='|S4')\n",
    "In[96]: data\n",
    "Out[96]: \n",
    "array([[-0.5099588 , -0.26549335,  0.47190496,  1.28825708],\n",
    "       [-0.22645075, -0.33822525,  1.15948599,  0.62708074],\n",
    "       [-1.05545525, -0.29507054,  1.8157602 , -0.23001171],\n",
    "       [-0.2477215 ,  0.16012906,  1.1783344 ,  1.8553623 ],\n",
    "       [-0.82402224,  1.02722829,  0.54261483, -0.20464688],\n",
    "       [ 1.22017486,  1.25984082,  1.39068215, -0.61045326],\n",
    "       [ 1.40302308, -0.73592691,  1.28374355,  0.08466187]])\n",
    "각각의 이름은 data 배열의 각 로우에 대응한다고 가정하자. 만약에 전체 로우에서 'Bob'과 같은 이름을 선택하려면 산술연산과 마찬가지로 배열에 대한 비교연산(== 같은) 도 벡터화 된다.\n",
    "\n",
    "이 불리언 배열은 배열의 색인으로 사용할 수 있다.\n",
    "\n",
    "이 불리언 배열은 반드시 색인하려는 축의 길이와 동일한 길이를 가져야 한다. 불리언 배열 색인도 슬라이스 또는 숫자 색인과 함께 혼용할 수 있다.\n",
    "\n",
    "\n",
    "In[101]: names == 'Bob' # names에서 'Bob' 인 것들은 True 아니면 False\n",
    "Out[101]: array([ True, False, False,  True, False, False, False], dtype=bool)\n",
    "In[102]: data[names == 'Bob']  # 0, 3에서 True\n",
    "Out[102]: \n",
    "array([[-0.5099588 , -0.26549335,  0.47190496,  1.28825708],\n",
    "       [-0.2477215 ,  0.16012906,  1.1783344 ,  1.8553623 ]])\n",
    "In[103]: data[names == 'Bob', 2:] # 0,3 의 배열중에 3번째 부터 끝까지 뱉어라\n",
    "Out[103]: \n",
    "array([[ 0.47190496,  1.28825708],\n",
    "       [ 1.1783344 ,  1.8553623 ]])\n",
    "Q) 0,3 번째를 참조하는 값 어케?\n",
    "\n",
    "'Bob'이 아닌 요소를 선택하려면 != 연산자를 사용하거나 -를 사용해서 조건절을 부정하면 된다.\n",
    "\n",
    "name != 'Bob'\n",
    "data[-(names == 'Bob')]\n",
    "\n",
    "세 가지 이름 중에서 두 가지 이름을 선택하려면 &(and) 와 |(or) 같은 논리연산자를 사용한 여러 개의 불리언 조건을 조합하여 사용하면 된다.\n",
    "\n",
    "In[107]: mask = (names == 'Bob') | (names == 'Will')\n",
    "\n",
    "In[108]: mask #1,3,4,5만 True\n",
    "\n",
    "In[107]: mask = (names == 'Bob') | (names == 'Will')\n",
    "In[108]: mask #1,3,4,5만 True\n",
    "Out[108]: array([ True, False,  True,  True,  True, False, False], dtype=bool)\n",
    "In[109]: data[mask] # 1,3,4,5 값만 내놔라\n",
    "Out[109]: \n",
    "array([[-0.5099588 , -0.26549335,  0.47190496,  1.28825708],\n",
    "       [-1.05545525, -0.29507054,  1.8157602 , -0.23001171],\n",
    "       [-0.2477215 ,  0.16012906,  1.1783344 ,  1.8553623 ],\n",
    "       [-0.82402224,  1.02722829,  0.54261483, -0.20464688]])\n",
    "배열에 불리언 색인을 이용해서 데이터를 선택하면 반환되는 배열의 내용이 바뀌지 않더라도 항상 데이터 복사가 이루어진다.\n",
    "\n",
    "불리언 배열에 값을 대입하는 것은 상식선에서 이루어지며, data에 저장된 모든 음수를 0으로 대입하려면 아래와 같이 하면 된다.\n",
    "data[data <0] = 0\n",
    "data[names != 'Joe'] = 7\n",
    "\n",
    "4.1.6 팬시 색인\n",
    "팬시 색인은 정수 배열을 사용한 색인을 설명하기 위해 NumPy에서 차용한 단어다. 8X4 크기의 배열이 있다고 하자.\n",
    "\n",
    "In[120]: arr = np.empty((8, 4)) #초기화 되지 않은 4개의 값을 같는 리스트 8개로 된 배열만들기\n",
    "In[121]: for i in range(8): # 0~7까지의 숫자를 i에 반복문, array 색인 마다 같은 번호 부여\n",
    "...     arr[i] = i\n",
    "In[123]: arr\n",
    "Out[121]: \n",
    "array([[ 0.,  0.,  0.,  0.],\n",
    "       [ 1.,  1.,  1.,  1.],\n",
    "       [ 2.,  2.,  2.,  2.],\n",
    "       [ 3.,  3.,  3.,  3.],\n",
    "       [ 4.,  4.,  4.,  4.],\n",
    "       [ 5.,  5.,  5.,  5.],\n",
    "       [ 6.,  6.,  6.,  6.],\n",
    "       [ 7.,  7.,  7.,  7.]])\n",
    "특정한 순서로 로우를 선택하고 싶다면 그냥 원하는 순서가 명시된 정수가 담긴 ndarray나 리스트를 넘기면 된다.\n",
    "\n",
    "In[125]: arr[[4, 3, 0, 6]] # array중 5번째, 4번째, 1번째, 7번째 참조\n",
    "Out[123]: \n",
    "array([[ 4.,  4.,  4.,  4.],\n",
    "       [ 3.,  3.,  3.,  3.],\n",
    "       [ 0.,  0.,  0.,  0.],\n",
    "       [ 6.,  6.,  6.,  6.]])\n",
    "\n",
    "다차원 색인 배열을 넘기는 것은 조금 다르게 동작하며, 각각의 색인 튜플에 대응하는 1차원 배열이 선택된다. \n",
    "\n",
    "In[131]: arr = np.arange(32).reshape((8,4)) # 4개의 값을 가진 리스트 8개를 반환하는데 0~31의 값을 갖게 한다.\n",
    "In[132]: arr\n",
    "Out[130]: \n",
    "array([[ 0,  1,  2,  3],\n",
    "       [ 4,  5,  6,  7],\n",
    "       [ 8,  9, 10, 11],\n",
    "       [12, 13, 14, 15],\n",
    "       [16, 17, 18, 19],\n",
    "       [20, 21, 22, 23],\n",
    "       [24, 25, 26, 27],\n",
    "       [28, 29, 30, 31]])\n",
    "In[133]: arr[[1, 5, 7, 2], [0, 3, 1, 2]]\n",
    "'''2번째 배열에서 첫 번째 값, 6번째 배열에서 4번째 값, 8번째 베열에서 2번째 값, 3번째 배열에서 3번째 값'''\n",
    "Out[131]: array([ 4, 23, 29, 10])\n",
    "이 예제를 잠시 살펴보자 (1,0), (5,3), (7,1) (2,2)에 대응하는 요소가 선택 되었다. 이 예제에서 팬시 색인은 우리의 예상과는 조금 다르게 동작했다. \n",
    "\n",
    "행렬의 행과 열에 대응하는 사각형 모양의 값이 선택되기를 기대했는데 사실 그렇게 하려면 다음처럼 선택해야 한다.\n",
    "\n",
    "In[135]: arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]] # 2, 6, 8, 3 행에서 1, 4, 2, 3순서로 담은 배열을 갖게 해라\n",
    "Out[133]: \n",
    "array([[ 4,  7,  5,  6],\n",
    "       [20, 23, 21, 22],\n",
    "       [28, 31, 29, 30],\n",
    "       [ 8, 11,  9, 10]])\n",
    "np.ix_ 함수를 사용하면 같은 결과를 얻을 수 있는데, 1차원 정수 배열 2개를 사각형 영역에서 사용할 색인으로 변환해준다.\n",
    "\n",
    "In[138]: arr[np.ix_([1, 5, 7, 2], [0, 3, 1, 2])]\n",
    "Out[135]: \n",
    "array([[ 4,  7,  5,  6],\n",
    "       [20, 23, 21, 22],\n",
    "       [28, 31, 29, 30],\n",
    "       [ 8, 11,  9, 10]])\n",
    "팬시 색인은 슬라이싱과는 달리 선택된 데이터를 새로운 배열로 복사한다.\n",
    "\n",
    "4.1.7 배열 전치와 축 바꾸기\n",
    "배열 전차는 데이터를 복사하지 않고 데이터 모양이 바귄 뷰를 반환하는 특별한 기능이다. ndarray는 transpose 메서드와 T라는 이름의 특수한 속성을 가지고 있다.\n",
    "\n",
    "In[139]: arr = np.arange(15).reshape((3, 5))\n",
    "In[140]: arr\n",
    "Out[137]: \n",
    "array([[ 0,  1,  2,  3,  4],\n",
    "       [ 5,  6,  7,  8,  9],\n",
    "       [10, 11, 12, 13, 14]])\n",
    "In[141]: arr.T\n",
    "Out[138]: \n",
    "array([[ 0,  5, 10],\n",
    "       [ 1,  6, 11],\n",
    "       [ 2,  7, 12],\n",
    "       [ 3,  8, 13],\n",
    "       [ 4,  9, 14]])\n",
    "행렬 계산을 할 때 자주 사용하게 될 텐데, 예를 들면 행렬의 내적 \n",
    " 는 np.dot을 이용해서 구할 수 있다.\n",
    "In[143]: arr = np.random.randn(6, 3)\n",
    "In[144]: np.dot(arr.T, arr)\n",
    "Out[141]:  # (3,6) X (6,3)\n",
    "array([[ 6.22450725,  1.06558449, -0.83079853],\n",
    "       [ 1.06558449,  2.82535758,  1.06919888],\n",
    "       [-0.83079853,  1.06919888,  4.34671241]])\n",
    "다차원 배열의 경우 transpose 메서드는 튜플로 축 번호를 받아서 치환한다. 실제로 계산하려면 머리에 쥐가 날지도 모른다.\n",
    "\n",
    "In[145]: arr = np.arange(16).reshape((2, 2, 4))\n",
    "In[146]: arr\n",
    "Out[143]: \n",
    "array([[[ 0,  1,  2,  3],\n",
    "        [ 4,  5,  6,  7]],\n",
    "\n",
    "       [[ 8,  9, 10, 11],\n",
    "        [12, 13, 14, 15]]])\n",
    "In[147]: arr.transpose((1,0,2))\n",
    "Out[144]: \n",
    "array([[[ 0,  1,  2,  3],\n",
    "        [ 8,  9, 10, 11]],\n",
    "\n",
    "       [[ 4,  5,  6,  7],\n",
    "        [12, 13, 14, 15]]])\n",
    "\n",
    ".T 속성을 이용하는 간단한 전치는 축을 뒤바꾸는 특별한 경우다. ndarray에는 swapaxes 메서드가 있는데 2개의 축 번호를 받아서 배열을 뒤바꾼다.\n",
    "\n",
    "In[148]: arr\n",
    "Out[145]: \n",
    "array([[[ 0,  1,  2,  3],\n",
    "        [ 4,  5,  6,  7]],\n",
    "\n",
    "       [[ 8,  9, 10, 11],\n",
    "        [12, 13, 14, 15]]])\n",
    "In[149]: arr.swapaxes(1, 2)\n",
    "Out[146]: \n",
    "array([[[ 0,  4],\n",
    "        [ 1,  5],\n",
    "        [ 2,  6],\n",
    "        [ 3,  7]],\n",
    "\n",
    "       [[ 8, 12],\n",
    "        [ 9, 13],\n",
    "        [10, 14],\n",
    "        [11, 15]]])\n",
    "swapaxes도 마찬가지로 데이터를 복사하지 않고 원래 데이터에 대한 뷰를 반환한다.\n",
    "\n",
    "4.2 유니버설 함수 ufunc라고 불리는 유니버설 함수는 ndarray 안에 있는 데이터 원소별로 연산을 수행하는 함수다. 유니버설 함수는 하나 이상의 스칼라 값을 받아서 하나 이상의 스칼라 결과 값을 반환하는 간단한 함수를 고속으로 수행할 수 있는 벡터화된 래퍼 함수라고 생각하면 된다.\n",
    "\n",
    "sqrt나 exp같은 간단한 변형을 전체 원소에 적용할 수 있다.\n",
    "\n",
    "이 경우는 단항 유니버설 함수라 하고,\n",
    "\n",
    "add나 maximum처럼 2개의 인자를 취해서 단일 배열을 반환하는 함수를 이항 유니버설 함수라고 한다.\n",
    "\n",
    "In[150]: x = np.random.randn(8)\n",
    "In[151]: y = np.random.randn(8)\n",
    "In[152]: x\n",
    "Out[149]: \n",
    "array([ 0.57483741,  0.39598833, -0.35815866, -1.73518055,  1.09899127,\n",
    "        0.81740202,  0.82778791, -0.34151437])\n",
    "In[153]: y\n",
    "Out[150]: \n",
    "array([ 0.92638336,  0.70822114,  0.66838903,  0.76546891,  0.22617098,\n",
    "       -1.29688062,  1.9109471 ,  2.54965647])\n",
    "In[154]: np.maximum(x, y)\n",
    "Out[151]: \n",
    "array([ 0.92638336,  0.70822114,  0.66838903,  0.76546891,  1.09899127,\n",
    "        0.81740202,  1.9109471 ,  2.54965647])\n",
    "\n",
    "배열 여러개를 반환\n",
    " 저작자 표시 신고\n",
    "'Python for data analysis' 카테고리의 다른 글\n",
    "Chapter 5 pandas 시작하기  (0)\t2016.03.25\n",
    "Chapter 4. Numpy 기본 : 배열과 벡터 계산  (0)\t2016.03.11\n",
    "Chapter 3. IPython 소개  (0)\t2016.03.11\n",
    "Chapter 2 사례 소개  (0)\t2016.03.04\n",
    "Chaper 1 시작하기 전에  (0)\t2016.03.04\n",
    "posted by 신퐁\n",
    "0 0\n",
    "2016.03.11 14:36 Python for data analysis\n",
    "Chapter 3. IPython 소개\n",
    "Chapter 3. IPython 소개\n",
    "\n",
    "무위로 행하고, 편안하게 일하라, 작은 것을 크게 여기고, 적은 것을 많게 여겨라, 어려운 일은 쉬울 때 처리하고 큰 일은 작은 것부터 처리하라. - 노자, 도덕경\n",
    "\n",
    "작가는 'IPython과 텍스트 편집기'를 사용한다고 한다.\n",
    "\n",
    "근본적으로 IPython은 대화형 컴퓨팅과 소프트웨어 개발 두 가지 모두를 위해 최적의 생산성을 얻도록 설계 되었다. 그리고 다른 프로그래밍 언어와 달리 '편집-컴파일-실행'방식보다 '실행-탐색'방식을 장려하고 있다. \n",
    "또한 운영체제의 셸, 파일 시스템과도 잘 통합되어 있다. \n",
    "\n",
    "이런 특징 덕분에 데이터 분석 프로그래밍에서 많은 부분을 차지하는 데이터 탐색, 실험, 오류 판독, 반복 등을 IPython에서는 빠르게 처리할 수 있다.\n",
    "\n",
    "IPython 프로젝트는 진보된 대화형 파이썬 셸 그 이상이며, GUI 콘솔에서 바로 확인할 수 있는 표와 웹 기반의 대화형 노트북 형식, 가볍고 빠른 병렬 컴퓨팅 엔진을 포함한다. 또한 개발자를 위한 다른 도구와 마찬가지로 개인화가 가능하다. \n",
    "\n",
    "Ipython은 cmd에서 실행 가능하다.\n",
    "\n",
    "3.1.1 탭 자동 완성\n",
    "\n",
    "겉으로 보기에 IPython은 대화형 파이썬 인터프리터와는 조금 다르다. 매스태티카 사용자라면 번호가 붙어있는 입 출력 프롬프트가 친숙하게 느껴질 것이다. 셸에서 입력을 하는 동안 <Tab>을 누르면 네임스페이스에서 그 시점까지 입력한 내용과 맞아떨어지는 변수(객체, 함수 등)를 자동으로 찾아준다.\n",
    "\n",
    "NOTE (TAB)을 눌렀을 때 화면에 출력 결과가 너무 많으면 초보자는 헷갈릴 수 있는데, IPython은 아예_로 시작하는 내부 메서드와 속성을 제외시키고 보여준다. 먼저 _를 입력하면 해당 메서드와 속성을 선택할 수 있다. 기본적으로 이런 메서드를 탭 자동 완성에 넣고 싶다면 IPython 환경 설정에서 설정할 수 있다.\n",
    "\n",
    "나중에 살펴볼 %run 명령어와 함께 조합해서 사용하면 키 입력을 대폭 줄일 수 있다. 또한 자동 완성 기능을 사용하면 함수에서 이름을 가진 인자도 = 기호까지 포함해서 보여준다.\n",
    "\n",
    "3.1.2 자기관찰\n",
    "변수 이름 앞이나 뒤에 ? 기호를 붙이면 그 객체에 대한 일반 정보를 출력한다.\n",
    "함수에도 마찬가지이다.\n",
    "??를 사용하면 함수의 소스코드를 보여준다.\n",
    "\n",
    "또 ?는 표준 유닉스나 윈도우 명령행에서와 마찬가지로 IPython의 네임스페이스를 검색하는 데 사용할 수도 있다. *기호로 둘러싸인 문자열과 포함하는 모든 이름을 보여준다. 예를 들어 Numpy의 최상단 네임스페이스 안에서 load를 포함하는 모든 함수 목록을 가져올 수 있다.\n",
    "\n",
    "3.1.3 %run 명령어\n",
    "%run 명령어를 사용하면 IPython 세션 안에서 파이썬 프로그램 파일을 불러와 실행할 수 있다. \n",
    "\n",
    "실행 중인 코드 중지하기\n",
    "%run을 통해 스크립트가 실행되고 있거나 오랜 실행 시간이 필요한 코드가 실행되고 있는 중간에 <ctrl+C> 를 누르면 KeyboardInterrupt 예외를 발생시킨다. 이 예외는 몇몇 특수한 경우를 제외한 거의 모든 파이썬 프로그램을 즉시 멈추도록 한다.\n",
    "\n",
    "TIP. 실행 중인 파이썬 코드가 확장 모듈을 호출한 경우에는 <Ctrl +C>를 눌러도 프로그램이 즉각 멈추지 않는데, 이런 경우에는 프로그램의 제어권이 파이썬 인터프리터로 되돌아올 때까지 기다리거나 심각한 경우에는 운영체제의 작업관리자 메뉴를 통해 파이썬 프로세스를 강제로 종료해야 한다.\n",
    "\n",
    "3.1.4 클립보드에 있는 코드 실행하기\n",
    "\n",
    "IPython에서 쉽고 빠르게 코드를 실행하려면 클립보드에 있는 내용을 붙여넣어 실행하면 된다. 이 방법은 다소 번거로워 보이지만 실제로 매우 유용하다.\n",
    "\n",
    "예를 들어, 복잡하거나 실행 시간이 오래 걸리는 애플리케이션을 개발하면서 스크립트를 단위별로 조각내어 실행해보고 싶은 경우나 매 단계별로 현재까지 읽어들인 데이터와 결과를 확인해보고 싶은 경우, 혹은 인터넷에서 찾은 코드를 실행해보고 싶은데 새로 .py 파일을 만들기는 귀찮을 때 유용하게 사용할 수 있다.\n",
    "\n",
    "<Ctrl + Shift + V >를 누르면 클립보드 내용이 붙여넣기 된다.\n",
    "클립 보드의 각 줄을 IPython에 한 줄씩 입력하는 방식으로 붙여넣기 한다.\n",
    " 줄 바꿈을 <return>으로 처리한다.\n",
    "\n",
    "x =5 \n",
    "y = 7\n",
    "if x > 5:\n",
    "    x += 1\n",
    "\n",
    "\n",
    "    y = 8\n",
    "\n",
    "이 스크립트를 붙여 넣기 한다면 indentical 오류가 발생한다.\n",
    "이 경우 %paste 혹은 %cpaste 매직 함수를 이용한다.\n",
    "\n",
    "%paste는 클립보드에 있는 텍스트를 단일 블록으로 실행한다.\n",
    "\n",
    "%cpaste는 %paste와 유사하지만 코드를 붙여넣을 때 특수한 프롬프트를 제공한다.\n",
    "실수로 잘못된 코드를 붙여 넣었다면 <Ctrl+C>를 눌러 %cpaste 프롬프트를 빠져나올 수 있다.\n",
    "\n",
    "\n",
    "3.1.5 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " 저작자 표시 신고\n",
    "'Python for data analysis' 카테고리의 다른 글\n",
    "Chapter 5 pandas 시작하기  (0)\t2016.03.25\n",
    "Chapter 4. Numpy 기본 : 배열과 벡터 계산  (0)\t2016.03.11\n",
    "Chapter 3. IPython 소개  (0)\t2016.03.11\n",
    "Chapter 2 사례 소개  (0)\t2016.03.04\n",
    "Chaper 1 시작하기 전에  (0)\t2016.03.04\n",
    "posted by 신퐁\n",
    "0 0\n",
    "2016.03.04 17:13 Python for data analysis\n",
    "Chapter 2 사례 소개\n",
    "이 책은 데이터를 생산적으로 다루는 여러 가지 파이썬 도구를 사용하는 방법을 설명한다.\n",
    "\n",
    "저마다 데이터를 처리하는 목적은 다르겠지만 대개는 다음과 같은 작업을 위해 사용할 것이다.\n",
    "\n",
    "외부 자료 활용 : 여러 가지 파일 형식과 데이터베이스를 읽고 쓰는 작업\n",
    "데이터 준비 : 데이터 정비, 수집, 집계, 정규화, 개조, 분리, 분석을 위한 이터 변형\n",
    "데이터 변형 : 모아놓은 데이터에 수학적, 통계학적 연산을 적용해 새로운 데이터를 도출. \n",
    "모델링과 계산 : 통계 모델, 기계 학습 알고리즘 또는 다른 계산 도구와 데이터 연결하기\n",
    "데이터 표현 : 정적 혹은 인터랙티브한 도식화 또는 원문 요약\n",
    "\n",
    "2.1 bit.ly의 1.usa.gov 데이터\n",
    "\n",
    "http://1usagov.measuredvoice.com/2012/\n",
    "\n",
    "에 가서 usagov_bitly_data2012-03-16-1331923249를 받고 압축을 푼뒤 txt파일로 변환하여 주었다.\n",
    "\n",
    "json모듈의 loads 함수는 내려받은 샘플 파일을 한 줄 씩 읽는다.\n",
    "\n",
    "path = 'E:\\\\Pfd\\\\usagov_bitly_data2012-03-16-1331923249.txt'\n",
    "open(path).readline()\n",
    "import json\n",
    "path = 'usagov_bitly_data2012-03-16-1331923249.txt'\n",
    "records = [json.loads(line) for line in open(path)]  # json 모듈의 loads 함수는 내려받은 샘플 파일을 한 줄 씩 읽는다.\n",
    "records[0]\n",
    "records[0]['tz'] # record의 개별 아이템에서 접근하려는 값의 키를 문자열로 넘겨서 쉽게 읽어올 수 있다.\n",
    "print records[0]['tz'] # 'America/New_York을 출력 형식으로 \n",
    "2.1.1 순수 파이썬으로 표준시간대 세어보기\n",
    "\n",
    "가장 빈도가 높은 표준시간대 (tz 필드)를 구한다고 가정하자. \n",
    "\n",
    "# 2.1.1\n",
    "time_zones = [rec['tz'] for rec in records] #수행하면 오류 - records의 아이템이 모두 표준시간대 필드를 포함하지 않음.\n",
    "time_zones = [rec['tz'] for rec in records if 'tz' in rec] # 위의 문제를 해결, tz 필드가 있는지 검사\n",
    "time_zones[:10] # 처음 10개의 표준시간대 보기, 몇 개는 비어있다. 그냥 두고 표준시간대를 셀 때 pandas를 사용.\n",
    "\n",
    "# 재사용이 쉽도록 이 로직을 함수로 만들고 time_zones 리스트를 함수에 넘겨서 사용\n",
    "def get_counts(sequence):\n",
    "    counts = {}\n",
    "    for x in sequence:\n",
    "        if x in counts:\n",
    "            counts[x] += 1\n",
    "        else:\n",
    "            counts[x] = 1\n",
    "    return counts    # time_zones를 순회하면서 표준시간대를 센 후 자료 구조에 저장\n",
    "\n",
    "from collections import defaultdict\n",
    "def get_counts2(sequence):\n",
    "    counts = defaultdict(int) # 값은 0부터 시작할 것임\n",
    "    for x in sequence:\n",
    "        counts[x] += 1\n",
    "    return counts\n",
    "\n",
    "counts = get_counts(time_zones)\n",
    "counts['America/New_York'] # 표준시간대 중 America/New_York의 표준 시간대 개수\n",
    "len(time_zones) #time_zones의 문자 길이\n",
    "\n",
    "#가장 많이 등장하는 상위 10개의 표준시간대를 알고 싶을때, 세련된 방법으로 사전 이용\n",
    "def top_counts(count_dict, n=10):\n",
    "    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]\n",
    "    value_key_pairs.sort() # 오름차순 정렬\n",
    "    return value_key_pairs[-n:]\n",
    "\n",
    "top_counts(counts) # 가장 많이 등장하는 상위 10개 표준시간대 알 수 있다.\n",
    "\n",
    "#collections.Counter 클래스를 이용하면 지금까지 수행했던 작업을 훨씬 쉽게 할 수 있다.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(time_zones)\n",
    "counts.most_common(10)\n",
    "2.1.2 pandas로 표준시간대 세어보기\n",
    "\n",
    "pandas의 주요 자료 구조는 DataFrame인데 표나 스프레드시트 같은 형태라고 생각하면 된다. 다음은 records를 가지고 DataFrame을 만드는 방법으로, 매우 간단하다.\n",
    "\n",
    "In[27]: from pandas import DataFrame, Series\n",
    "import pandas as pd; import numpy as np\n",
    "\n",
    "In[28]: from pandas import DataFrame, Series\n",
    "\n",
    "In[29]: import pandas as pd; import numpy as np\n",
    "\n",
    "In[30]: frame = DataFrame(records)\n",
    "\n",
    "In[31]: frame\n",
    "\n",
    "Out[31]: \n",
    "      _heartbeat_                                                  a  \\\n",
    "0             NaN  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
    "1             NaN                             GoogleMaps/RochesterNY   \n",
    "2             NaN  Mozilla/4.0 (compatible; MSIE 8.0; Windows NT ...   \n",
    "3             NaN  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8)...   \n",
    "4             NaN  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
    "5             NaN  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...   \n",
    "In[33]: frame['tz'][:10]\n",
    "\n",
    "Out[33]: \n",
    "0     America/New_York\n",
    "1       America/Denver\n",
    "2     America/New_York\n",
    "3    America/Sao_Paulo\n",
    "4     America/New_York\n",
    "5     America/New_York\n",
    "6        Europe/Warsaw\n",
    "7                     \n",
    "8                     \n",
    "9                     \n",
    "Name: tz, dtype: object\n",
    "In[34]: tz_counts = frame['tz'].value_counts() # 각 시간대 별 갯수를 센다\n",
    "tz_counts[:10] # 상위 10개 정렬\n",
    "\n",
    "Out[34]: \n",
    "America/New_York       1251\n",
    "                        521\n",
    "America/Chicago         400\n",
    "America/Los_Angeles     382\n",
    "America/Denver          191\n",
    "Europe/London            74\n",
    "Asia/Tokyo               37\n",
    "Pacific/Honolulu         36\n",
    "Europe/Madrid            35\n",
    "America/Sao_Paulo        33\n",
    "Name: tz, dtype: int64\n",
    "matplotlib 라이브러리로 이 데이터의 그래프 그려보기.\n",
    "\n",
    "In[38]: clean_tz = frame['tz'].fillna('Missing') # fillna로 없는 값을 대체\n",
    "In[39]: clean_tz[clean_tz ==''] = 'Unknown' # 비어있는 값은 불리언 배열 색인을 통해 대체\n",
    "In[40]: tz_counts = clean_tz.value_counts() # tz_count에서 비어있는 표준시간대를 다른 이름으로 바꿔줌\n",
    "In[41]: tz_counts[:10]\n",
    "Out[41]: \n",
    "America/New_York       1251\n",
    "Unknown                 521\n",
    "America/Chicago         400\n",
    "America/Los_Angeles     382\n",
    "America/Denver          191\n",
    "Missing                 120\n",
    "Europe/London            74\n",
    "Asia/Tokyo               37\n",
    "Pacific/Honolulu         36\n",
    "Europe/Madrid            35\n",
    "Name: tz, dtype: int64\n",
    "tz_counts[:10].plot(kind= 'barh', rot=0) # plot 메서드 이용, counts 객체에 대한 수평 막대 그래프를 만든다.\n",
    "\n",
    "\n",
    "\n",
    "#다음처럼 URL을 축약하는 데 사용한 브라우저, 단말기, 애플리케이션에 대한 정보를 담은 필드가 있다.\n",
    "In[45]: frame['a'][1]\n",
    "Out[45]: u'GoogleMaps/RochesterNY'\n",
    "In[46]: frame['a'][50]\n",
    "Out[46]: u'Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2'\n",
    "In[47]: frame['a'][51]\n",
    "Out[47]: u'Mozilla/5.0 (Linux; U; Android 2.2.2; en-us; LG-P925/V10e Build/FRG83G) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1'\n",
    "'agent'라고 하는 이 흥미로운 문자열 정보를 분석하는 일이 어려워보일 수도 있다. 하지만 다행히도 파이썬의 내장 문자열 함수와 정규표현식을 익히고 나면 식은 죽 먹기다.\n",
    "\n",
    "이 둘을 이용하면 대략적인 브라우저 종류를 알 수 있는 첫번째 문자열 토큰을 잘라내고 사용자 행동에 대한 또 다른 개요를 만들 수 있다.\n",
    "\n",
    "In[50]: results = Series([x.split()[0] for x in frame.a.dropna()]) # a에서 공백으로 분리, split()\n",
    "In[51]: results[:5] # 5개 보여주기\n",
    "Out[51]: \n",
    "0               Mozilla/5.0\n",
    "1    GoogleMaps/RochesterNY\n",
    "2               Mozilla/4.0\n",
    "3               Mozilla/5.0\n",
    "4               Mozilla/5.0\n",
    "dtype: object\n",
    "In[52]: results.value_counts()[:8] # 8개 종류를 쓰는 순서대로 보여주기\n",
    "Out[52]: \n",
    "Mozilla/5.0                 2594\n",
    "Mozilla/4.0                  601\n",
    "GoogleMaps/RochesterNY       121\n",
    "Opera/9.80                    34\n",
    "TEST_INTERNET_AGENT           24ㅗ\n",
    "GoogleProducer                21\n",
    "Mozilla/6.0                    5\n",
    "BlackBerry8520/5.0.0.681       4\n",
    "dtype: int64\n",
    "표준시간대 순위표를 윈도우 사용자와 비윈도우 사용자 그룹으로 나눠보기\n",
    "\n",
    "agent 문자열이 'Windows'를 포함하면 윈도우 사용자라고 가정, agent값이 없는 경우 제외 시킨다.\n",
    "\n",
    "cframe = frame[frame.a.notnull()] #agent값이 없는 경우 제외\n",
    "\n",
    "각 행이 윈도우인지 아닌지 검사한다.\n",
    "\n",
    "\n",
    "\n",
    "2.2 MovieLens의 영화평점 데이터\n",
    "\n",
    "GroupLens 연구소는 1990년대부터 2000년대 초까지 방대한 영화 평점 데이터를 제공하고 있다.\n",
    "이 데이터에는 영화평점과 영화에 대한 정보(장르, 개봉연도) 그리고 사용자에 대한 정보( 나이, 우편번호, 성별, 직업)가 포함되어있다. 기계 학습 기법을 여기서 소개하기는 어렵고 이런 종류의 데이터를 요구사항에 맞게 잘 쪼개는 방법만 소개하겠다.\n",
    "\n",
    "MovieLens 1M( 백만 개) 데이터 셋은 약 6천여 명의 사용자들로부터 수집한 4000여 편의 영화에 대한 백만 개의 영화 평점을 담고 있다.\n",
    "\n",
    "이 데이터 셋은 평점, 사용자 정보, 영화 정보, 이 세 가지 테이블로 나뉘어 있는데, zip 파일을 풀어서 각 테이블을 pandas.read_table 함수를 사용해 DataFrame 객체로 불러오자.\n",
    "\n",
    " 저작자 표시 신고\n",
    "'Python for data analysis' 카테고리의 다른 글\n",
    "Chapter 5 pandas 시작하기  (0)\t2016.03.25\n",
    "Chapter 4. Numpy 기본 : 배열과 벡터 계산  (0)\t2016.03.11\n",
    "Chapter 3. IPython 소개  (0)\t2016.03.11\n",
    "Chapter 2 사례 소개  (0)\t2016.03.04\n",
    "Chaper 1 시작하기 전에  (0)\t2016.03.04\n",
    "posted by 신퐁\n",
    "0 0\n",
    "2016.03.04 12:20 Python for data analysis\n",
    "Chaper 1 시작하기 전에\n",
    "1.1 이 책은?\n",
    "파이썬으로 데이터를 다루는 다양한 기본적인 방법을 소개.\n",
    "\n",
    "1.2 왜 데이터 분석을 위한 파이썬인가?\n",
    "\n",
    "파이썬은 스크립트 언어라고 한다.\n",
    "\n",
    "이름 자체에 중요한 소프트웨어를 만드는 데는 사용하지 못한다는 의미를 함축한다.\n",
    "\n",
    "과확계산 컴퓨팅 커뮤니티에서 사용된다.\n",
    "\n",
    "1.2.1 접착제처럼 사용하는 파이썬\n",
    "\n",
    "C, C++, 포트란 코드와의 통합이 쉽다.\n",
    "\n",
    "프로그램은 실행 시간의 대부분을 차지하는 작은 부분의 코드와 실행 시간을 얼마 차지하지 않는 많은 양의 '글루 코드'로 이루어져 있다.\n",
    "\n",
    "1.2.2 한 가지 언어만 사용\n",
    "\n",
    "파이썬은 연구를 하거나 프로토 타입을 만드는 데 적합한 언어일 분만 아니라 실제 시스템을 개발하는 데도 적합하기에 갈수록 인기를 더하고 있다.\n",
    "\n",
    "1.2.3 파이썬을 사용하면 안 되는 경우.\n",
    "\n",
    "파이썬은 인터프리터 언어라 Java나 C++같은 컴파일 언어보다 많이 느리다.\n",
    "\n",
    "동시다발적인 멀티스레드를 처리하거나 CPU에 집중된 많은 스레드를 처리하는 애플리케이션에 적합한 언어는 아니다. GIL때문인데, 이 메커니즘은 인터프리터가 한 번에 하나의 파이썬 바이트 코드 명령만 실행하도록 한다.\n",
    "\n",
    "1.3 필수 파이썬 라이브러리\n",
    "지금부터 사용할 라이브러리와 과학계산용 파이썬 환경에 익숙하지 않은 독자를 위해 간단히 라이브러리를 소개한다.\n",
    "\n",
    "\n",
    "1.3.1 NumPy\n",
    "NumPy는 Numerical Python의 줄임말로, 과학계산용 파운데이션 패키지다.\n",
    "\n",
    " 기능:\n",
    "빠르고 효율적인 다차원 배열 객체 ndarray\n",
    "배열 원소를 다루거나 배열 간의 수학 계산을 수행하는 함수\n",
    "디스크로부터 배열 기반의 데이터를 읽거나 쓸 수 있는 도구\n",
    "선형대수 계산, 푸이에 변환, 난수 발생기\n",
    "파이썬과 C, C++그리고 포트란 코드를 통합하는 도구\n",
    "\n",
    "파이썬에 빠른 배열 처리 기능을 제공한다. 데이터 분석에서는 아록르짐에 사용할 데이터 컨테이너의 역하을 한다. 수치 데이터라면 NumPy 배열은 파이썬 기본 자료 구조보다 훨씬 효율적인 방법으로 데이터를 저장하고 다룰 수 있다. 또한 C나 포트란 같은 저수준 언어로 이뤄진 라이브러리는 NumPy 배열에 저장된 데이터를 복사하지 않고 사용할 수 있다.\n",
    "\n",
    "1.3.2 pandas\n",
    "pandas : 구조화된 데이터를 빠르고 쉬우면서도 다양한 형식으로 가공할 수 있는 풍부한 자료 구조와 함수를 제공한다. 파이썬을 강력하고 생산적인 데이터 분석 환경으로 만드는 데 꼭 필요하다.\n",
    "\n",
    "주로 pandas의 주요 객체인 DataFrame을 다룰 텐데, 이 객체는 2차원 표 또는 행과 열을 나타내는 자료 구조다.\n",
    "\n",
    "NumPy의 고성능 배열 계산 기능과 스프레드 시트, SQL 같은 관계형 데이터베이스의 유연한 데이터 조작 기능을 조합한 것이다. \n",
    "세련된 인덱싱 기능으로 쉽게 데이터를 재배치하고 잘게 조각내거나 집계하고 부분집합을 구할 수도 있다. \n",
    "\n",
    "1.3.3 matplotlib\n",
    "그래프나 2차원 데이터 시각화를 생성하는 유명한 파이썬 라이브러리.\n",
    "출판물에 필요한 그래프를 만드는 데 맞춰졌으며 IPython에 통합되어 있어 편리하게 데이터를 살펴보고 그래프를 만들어 낼 수 있다.\n",
    "\n",
    "1.3.4 IPython\n",
    "IPython은 표준 과학계산용 파이썬 도구 모음에 포함된 컴포넌트이며, 인터랙티브하고 강력한 생산적인 환경을 제공한다. 파이썬 코드를 작성하고 테스트하고 디버깅을 할 수 있는 향상된 파이썬 셸을 제공한다.\n",
    "특히 데이터를 처리하고 matplotlib으로 데이터를 시각화 하는 데 매우 유용하다. \n",
    "실행, 디버깅, 테스트 같은 파이썬을 필요로 하는 작업을 대부분 수행할 수 있다.\n",
    "\n",
    "IPython을 웹브라우저와 연결할 수 있는 매스메티카 스타일의 HTML 노트북 기능\n",
    "그래프를 즉시 그려보거나 여러 줄을 편집할 수 있는 기능 그리고 문법 강조 기능을 가진 Qt 프레임워크 기반의 GUI 콘솔\n",
    "\n",
    "병렬 분산 컴퓨팅을 위한 기반 구조\n",
    "\n",
    "1.3.5 SciPy\n",
    "과학계산 컴퓨팅 영역의 여러 기본 문제를 다루는 패키지 모음이다.\n",
    "\n",
    "scipy.integrate : 수치적분 루틴과 미분방정식 해법기\n",
    "scipy.linalg: numpy.linalg에서 제공하는 것보다 더 확장된 선형대수 루틴과 매트릭스 분해\n",
    "scipy.optimize : 함수 최적화기와 방정식의 근을 구하는 알고리즘\n",
    "scipy.signal : 시그널 프로세싱 도구\n",
    "scipy.sparse : 희소 행렬과 희소 선형 시스템 풀이법\n",
    "scipy.special : 감마 함수처럼 흔히 사용되는 수학 함수를 구현한 포트란 라이브러리인 SPECFUN 확장\n",
    "scipy.stats : 표준 연속/이산 확률 분포와 다양한 통계 테스트, 그리고 좀 더 기술적인 통계 도구\n",
    "scipy.weave : 배열 계산을 빠르게 하기 위해 인라인 C++ 코드를 사용하는 도구\n",
    "\n",
    "NumPy와 SciPy를 함께 사용하면 확장 애드온을 포함한 MATLAB를 완벽하게 대체 가능하다.\n",
    "\n",
    "1.4 설치와 설정\n",
    "1.4.1 윈도우\n",
    "1.4.2 애플 OS X\n",
    "1.4.3 리눅스 \n",
    "1.4.4 파이썬 2.x와 파이썬 3.x\n",
    "1.4.5 통합 개발 환경\n",
    "1.5 커뮤니티와 컨퍼런스\n",
    "1.6 이 책을 살펴보는 방법\n",
    "1.6.1 예제코드\n",
    "1.6.2 예제에 사용된 데이터\n",
    "\n",
    "1.6.3 import 컨벤션\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib..pyplot as plt\n",
    "\n",
    "1.6.4 용어\n",
    "\n",
    "의사 코드 :\n",
    "  알고리즘이나 과정을 실제 유효한 소스 코드는 아니지만 형식을 코드처럼 표현한 것\n",
    "\n",
    "신태틱 슈거 : \n",
    "  새로운 기능은 아니지만 기존에 비해 좀 더 편리하고 타이핑도 간편해지는 프로그래밍 문법\n",
    "\n",
    "1.7 감사의 말\n",
    "\n",
    " 저작자 표시 신고\n",
    "'Python for data analysis' 카테고리의 다른 글\n",
    "Chapter 5 pandas 시작하기  (0)\t2016.03.25\n",
    "Chapter 4. Numpy 기본 : 배열과 벡터 계산  (0)\t2016.03.11\n",
    "Chapter 3. IPython 소개  (0)\t2016.03.11\n",
    "Chapter 2 사례 소개  (0)\t2016.03.04\n",
    "Chaper 1 시작하기 전에  (0)\t2016.03.04\n",
    "posted by 신퐁\n",
    "0 0\n",
    "prev 1  next\n",
    "RSS FEED\n",
    "신퐁's Blog is powered by DAUM / designed by TISTORY\n",
    "\n",
    "Tistory로그인\n",
    "\n",
    "\n",
    "출처: http://sinpong.tistory.com/category/Python for data analysis [새로운 바람]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
